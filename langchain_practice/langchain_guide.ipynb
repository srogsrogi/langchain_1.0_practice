{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8f02cf",
   "metadata": {},
   "source": [
    "# Langchain 1.0\n",
    "\n",
    "- langchain 1.0 실습 가이드입니다.\n",
    "- 0버전과 문법 및 객체 구조가 매우 다르므로 GPT를 통한 코드 작성이 매우 어렵습니다. 반드시 작동이 확인된 예시 코드와 공식 문서를 기반으로 개발하시기 바랍니다.\n",
    "  - https://docs.langchain.com/oss/python/langchain/quickstart\n",
    "  - https://reference.langchain.com/python/langgraph/graphs/\n",
    "- markdown 셀의 header로 목차를 확인하고 코드 흐름을 따라가면서 이해되지 않는 개념이 있으면 함께 드린 마크다운 파일을 다시 읽어보세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52178c77",
   "metadata": {},
   "source": [
    "## 0. 환경 설정\n",
    "\n",
    "- Python 3.12.12 기반의 conda 가상 환경에서 테스트되었습니다.\n",
    "- environment.yml 또는 requirements.txt 파일을 통해 환경을 재현하실 수 있습니다.\n",
    "- 환경 변수만 잘 등록해준다면 venv, colab 등 다른 실행 환경에서도 작동할 것으로 예상되나 버전 정보를 잘 확인해주세요.\n",
    "- 코드를 위에서부터 순서대로 실행시키지 않을 경우 오류가 발생할 수 있습니다.\n",
    "- 개별 셀 단위로 실행할 때는 모듈 import, agent 및 model 객체 정의가 의도대로 되어 있는지 확인하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0a3602f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 라이브러리 import\n",
    "import os\n",
    "\n",
    "# 환경 변수 로드\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 예쁜 출력\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e246eb",
   "metadata": {},
   "source": [
    "## 1. langsmith 연결\n",
    "- langsmith는 langgraph / langchain Agent의 실행을 기록하고, 시각화 및 분석을 제공하는 Observability 플랫폼입니다.\n",
    "- 모든 입력을 tracing하여 입출력 확인, 토큰 사용량 및 비용 확인, 에러 로그 시각화, 지연시간 측정 등의 기능을 제공합니다.\n",
    "- 아래 세 가지 환경변수만 잘 등록해놓는다면, 따로 코드로 구현하지 않아도 Agent 실행에 대한 모든 로그를 langsmith에서 확인할 수 있습니다.\n",
    "  - LANGSMITH_TRACING\n",
    "  - LANGSMITH_API_KEY\n",
    "  - LANGSMITH_PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608ee30",
   "metadata": {},
   "source": [
    "## 2. 단일 Model 호출\n",
    "\n",
    "- Agent 없이 단일 Model을 호출하는 방법을 알아봅니다.\n",
    "- invoke()는 모델 또는 체인을 한 번 실행하여 모델의 응답을 반환받는 메서드입니다.\n",
    "- Agent와 체인을 만들기 전에, 단일 Model을 호출해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 채팅 모델 초기화의 가장 기본적인 형태\n",
    "# init_chat_model은 여러 모델을 초기화할 수 있는 범용적이고 간단한 함수입니다.\n",
    "# 그러나 모델별 세부 설정을 위해서는 각 모델 벤더들이 제공하는 모듈의 클래스를 활용하는 것이 좋습니다. 이 방법은 뒤에 등장하니, 실제 개발 시에는 그걸 사용하세요!\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"openai:gpt-5-nano\") # api key는 환경 변수에서 자동으로 로드됩니다. api_key 매개변수로 직접 전달할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e5f2abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='안녕! 오늘은 무엇을 도와줄까?\\n\\n- 간단한 질문에 답하기\\n- 한국어 학습 도움(문법, 표현, 발음 연습)\\n- 번역이나 의역\\n- 글쓰기 아이디어나 초안, 요약\\n- 코딩 문제 해결\\n- 여행 정보나 음식 레시피\\n\\n그 외에 하고 싶은 주제가 있다면 편하게 말해줘!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 546, 'prompt_tokens': 8, 'total_tokens': 554, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYmzM36K6pzZHD5lucD0hxZBHYLfn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e213b493-7a57-4c8f-ac13-fcf2530782a5-0', usage_metadata={'input_tokens': 8, 'output_tokens': 546, 'total_tokens': 554, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}})\n"
     ]
    }
   ],
   "source": [
    "# invoke 메서드로 독립적인 LLM API를 호출합니다.\n",
    "response = model.invoke('안녕')\n",
    "\n",
    "# 모델이 보내준 응답 전체를 출력하면, 토큰 사용량 등 메타 데이터가 함께 출력됩니다.\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e1a7b709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('안녕! 오늘은 무엇을 도와줄까?\\n'\n",
      " '\\n'\n",
      " '- 간단한 질문에 답하기\\n'\n",
      " '- 한국어 학습 도움(문법, 표현, 발음 연습)\\n'\n",
      " '- 번역이나 의역\\n'\n",
      " '- 글쓰기 아이디어나 초안, 요약\\n'\n",
      " '- 코딩 문제 해결\\n'\n",
      " '- 여행 정보나 음식 레시피\\n'\n",
      " '\\n'\n",
      " '그 외에 하고 싶은 주제가 있다면 편하게 말해줘!')\n"
     ]
    }
   ],
   "source": [
    "# 모델이 보내준 실제 답변 내용만 출력하려면 응답의 content 속성을 참조합니다.\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5f80f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화 시 다양한 파라미터를 지정할 수 있습니다.\n",
    "# OpenAI 모델 외 다양한 모델에 대해서도 동일한 파라미터로 요청을 보낼 수 있습니다.\n",
    "model = init_chat_model(\n",
    "    model = \"openai:gpt-5-nano\",\n",
    "    temperature=0.8, # 응답의 창의성. GPT-5 계열 모델들은 temperature 파라미터를 지원하지 않지만, Langchain에서는 일관된 인터페이스를 제공하기 때문에 오류가 발생하지 않습니다.\n",
    "    max_tokens=2000, # 최대 토큰 수\n",
    "    timeout=20, # 요청 제한 시간(초)\n",
    "    max_retries=2, # 요청 실패 시 재시도 횟수\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e47bc9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('현재 기본 모드로는 자동으로 실시간 웹 검색을 실행하지는 않아요. 제 답변은 제 학습 데이터와 지식 범위에 기반합니다. 다만 사용하는 '\n",
      " '플랫폼에 웹 검색/브라우징 기능이 있다면 그 기능으로 최신 정보를 찾아드릴 수 있습니다.\\n'\n",
      " '\\n'\n",
      " '원하시면 다음을 도와드릴 수 있어요.\\n'\n",
      " '- 웹 검색 기능이 활성화되어 있으면 제가 실시간 정보를 찾아 요약하고 출처를 제공합니다.\\n'\n",
      " '- 활성화되지 않았다면, 제가 최신 정보를 찾을 수 있도록 검색어를 함께 구성해 드리거나, 직접 찾아볼 수 있는 방법을 안내해 '\n",
      " '드립니다.\\n'\n",
      " '- 이미 알고 있는 웹 페이지가 있다면 그 링크를 주시면 요약이나 핵심 정리도 가능합니다.\\n'\n",
      " '\\n'\n",
      " '어떤 정보를 찾고 계신가요? 주제나 기간을 알려주시면 적합한 검색어를 제안해 드릴게요. 예를 들면:\\n'\n",
      " '- \"최근 AI 규제 동향 한국 2024년 이후\"\\n'\n",
      " '- \"맥북 M3 성능 비교\"\\n'\n",
      " '- \"한국 금융시장 오늘 시세 요약\"')\n"
     ]
    }
   ],
   "source": [
    "# 파라미터가 적용된 모델로도 다시 호출해봅시다.\n",
    "response = model.invoke('너 웹 서치 기능도 가지고 있니?') # 기본 모델은 웹 서치 기능을 가지고 있지 않습니다.\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394ccfe",
   "metadata": {},
   "source": [
    "## 3. Agent 생성\n",
    "\n",
    "- 아무 추가 기능 없는 단일 모델 호출하려고 Langchain을 쓰는 건 아니죠.\n",
    "- Langchain의 핵심 기능인 Agent를 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c49c5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 생성에 필요한 모듈입니다.\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# 앞서 초기화한 Model을 사용하여 Agent를 생성합니다.\n",
    "agent = create_agent(\n",
    "    model=model, # 사용할 LLM 모델을 미리 초기화(init)한 후 인자로 전달하세요.\n",
    "    tools=[] # tool은 필수 인자지만, 빈 리스트를 전달하면 아무 tool도 없는 Agent를 생성할 수 있습니다.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "45bc6985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='오늘 서울 날씨는 어때?', additional_kwargs={}, response_metadata={}, id='62fd436c-10bd-417f-99e3-33fa755c1cf4'),\n",
      "              AIMessage(content='죄송하지만 지금 실시간 날씨 정보에 접속할 수 없어 오늘의 서울 날씨를 바로 알려드릴 수 없어요. 다만 빠르게 확인하는 방법을 안내해 드릴게요.\\n\\n- 스마트폰의 기본 날씨 앱 확인\\n- 네이버 날씨나 다음 날씨 같은 포털 사이트의 서울 날씨 페이지\\n- 기상청 홈페이지에서 서울 지역 일기예보 확인\\n\\n원하시면 제가 바로 확인하는 방법을 따라가실 수 있도록 한두 가지 링크와 요약 화면 구성 방법도 정리해 드릴게요. 또한 오늘의 온도대에 맞춘 옷차림 팁이나 예상 강수 여부 등에 대한 일반적인 정보도 도움이 필요하신가요? 어떤 방식으로 도와드릴지 알려 주세요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1325, 'prompt_tokens': 14, 'total_tokens': 1339, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1152, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYmzbSUOhDyOdnAVISdohXFEixyy0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--0bfb549a-e806-4f98-b64f-234b18b738cc-0', usage_metadata={'input_tokens': 14, 'output_tokens': 1325, 'total_tokens': 1339, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1152}})]}\n"
     ]
    }
   ],
   "source": [
    "# 모델에 전달할 메시지를 OpenAI의 Chat API 형식에 맞게 작성합니다.\n",
    "# 다른 모델은 다른 형식을 요구할 수 있으니, 모델 문서를 참고하세요.\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"오늘 서울 날씨는 어때?\"},\n",
    "]\n",
    "\n",
    "# Agent를 통해 모델을 호출합니다. Agent에 대한 invoke는 모델 invoke와는 다르게 dictionary 형태의 입력을 받으니 주의하세요.\n",
    "# 검색 tool이 없기 때문에, 실시간 날씨 정보를 제공하지는 못할 것입니다.\n",
    "response = agent.invoke({\"messages\":messages})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "44446fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('죄송하지만 지금 실시간 날씨 정보에 접속할 수 없어 오늘의 서울 날씨를 바로 알려드릴 수 없어요. 다만 빠르게 확인하는 방법을 안내해 '\n",
      " '드릴게요.\\n'\n",
      " '\\n'\n",
      " '- 스마트폰의 기본 날씨 앱 확인\\n'\n",
      " '- 네이버 날씨나 다음 날씨 같은 포털 사이트의 서울 날씨 페이지\\n'\n",
      " '- 기상청 홈페이지에서 서울 지역 일기예보 확인\\n'\n",
      " '\\n'\n",
      " '원하시면 제가 바로 확인하는 방법을 따라가실 수 있도록 한두 가지 링크와 요약 화면 구성 방법도 정리해 드릴게요. 또한 오늘의 온도대에 '\n",
      " '맞춘 옷차림 팁이나 예상 강수 여부 등에 대한 일반적인 정보도 도움이 필요하신가요? 어떤 방식으로 도와드릴지 알려 주세요.')\n"
     ]
    }
   ],
   "source": [
    "# 실제 답변 내용만 출력하려면 messages 리스트의 마지막 요소의 content 속성을 참조합니다.\n",
    "pprint(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "755d41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 생성 시에도 다양한 파라미터를 지정할 수 있습니다.\n",
    "# 오늘 다 다뤄보지는 못하겠지만, Agent의 세부 동작은 모두 이 파라미터들로 조정할 수 있습니다.\n",
    "# 아래 있는 것들 외에도 더 많은 파라미터가 있으니 공식 문서를 참고하세요.\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[], # tool 리스트는 다음 챕터에서 다뤄보겠습니다.\n",
    "    system_prompt=\"You are a helpful assistant.\", # Agent의 시스템 프롬프트입니다.\n",
    "    middleware=[], # Agent의 동작 사이에 발생하는 요청이나 응답을 가로채서 처리하는 고급 기능입니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3787492",
   "metadata": {},
   "source": [
    "## 4. tool 정의\n",
    "\n",
    "- 위에서 만든 Agent는 별다른 기능이 없으니 단일 모델 호출과 별로 다를 게 없죠.\n",
    "- 이제 Agent가 사용할 tool을 만들어 봅시다.\n",
    "- tool의 종류를 세 가지로 나누어 각각 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5de40",
   "metadata": {},
   "source": [
    "### 4-1. 커스텀 tool 정의\n",
    "\n",
    "- 직접 만든 Python 함수를 tool로 사용할 수 있습니다.\n",
    "- URL 또는 라이브러리를 통해 API를 호출하여 응답을 반환하는 tool도 이 방법으로 구현할 수 있습니다.\n",
    "- tool을 만들 때 typehint와 docstring을 잘 작성해주는 것이 매우 중요합니다! 에이전트가 도구를 선택할 때 참조합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "075f2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool 정의를 위해 필요한 모듈입니다.\n",
    "from langchain.tools import tool\n",
    "\n",
    "# 커스텀 tool 생성\n",
    "@tool # 데코레이터를 사용하여 tool로 등록합니다.\n",
    "def calculator(num_1:int, num_2:int) -> int: # typehint는 Agent가 tool의 입출력 형식을 이해하는 데 도움을 줍니다. 안정적인 작동을 위해 반드시 작성하는게 좋습니다.\n",
    "    \"\"\"입력받은 두 수의 덧셈을 반환합니다.\"\"\" # docstring은 tool의 설명으로 사용됩니다. Agent가 tool을 선택하는 데 도움을 줍니다.\n",
    "    return num_1 + num_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf31f3a",
   "metadata": {},
   "source": [
    "### 4-2. langchain-community에 통합된 외부 tool 사용\n",
    "\n",
    "- 라이브러리를 통해 제공되는 외부 tool들을 langchain-community에서 통합하여 사용할 수 있습니다.\n",
    "- 웬만한 기능들은 langchain 생태계 내에서 쉽게 쓸 수 있으니 목록을 확인하고 활용해봅시다.\n",
    "- https://docs.langchain.com/oss/python/integrations/providers/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ef36ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ainetwork\n",
      "amadeus\n",
      "arxiv\n",
      "asknews\n",
      "audio\n",
      "azure_ai_services\n",
      "azure_cognitive_services\n",
      "bearly\n",
      "bing_search\n",
      "brave_search\n",
      "cassandra_database\n",
      "clickup\n",
      "cogniswitch\n",
      "connery\n",
      "convert_to_openai\n",
      "databricks\n",
      "dataforseo_api_search\n",
      "dataherald\n",
      "ddg_search\n",
      "e2b_data_analysis\n",
      "edenai\n",
      "eleven_labs\n",
      "few_shot\n",
      "file_management\n",
      "financial_datasets\n",
      "github\n",
      "gitlab\n",
      "gmail\n",
      "golden_query\n",
      "google_books\n",
      "google_cloud\n",
      "google_finance\n",
      "google_jobs\n",
      "google_lens\n",
      "google_places\n",
      "google_scholar\n",
      "google_search\n",
      "google_serper\n",
      "google_trends\n",
      "graphql\n",
      "human\n",
      "ifttt\n",
      "interaction\n",
      "jina_search\n",
      "jira\n",
      "json\n",
      "memorize\n",
      "merriam_webster\n",
      "metaphor_search\n",
      "mojeek_search\n",
      "multion\n",
      "nasa\n",
      "nuclia\n",
      "office365\n",
      "openai_dalle_image_generation\n",
      "openapi\n",
      "openweathermap\n",
      "passio_nutrition_ai\n",
      "playwright\n",
      "plugin\n",
      "polygon\n",
      "powerbi\n",
      "pubmed\n",
      "render\n",
      "requests\n",
      "riza\n",
      "scenexplain\n",
      "searchapi\n",
      "searx_search\n",
      "semanticscholar\n",
      "shell\n",
      "slack\n",
      "sleep\n",
      "spark_sql\n",
      "sql_database\n",
      "stackexchange\n",
      "steam\n",
      "steamship_image_generation\n",
      "tavily_search\n",
      "vectorstore\n",
      "wikidata\n",
      "wikipedia\n",
      "wolfram_alpha\n",
      "yahoo_finance_news\n",
      "you\n",
      "youtube\n",
      "zapier\n",
      "zenguard\n"
     ]
    }
   ],
   "source": [
    "# langchain community에서 통합되어 있는 외부 tool의 목록을 확인해봅시다.\n",
    "import importlib, pkgutil\n",
    "\n",
    "package = importlib.import_module(\"langchain_community.tools\")\n",
    "\n",
    "for mod in pkgutil.iter_modules(package.__path__):\n",
    "    print(mod.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "abadc23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DuckDuckGoSearchRun', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'tool']\n"
     ]
    }
   ],
   "source": [
    "# duckduckgo는 api key 없이도 사용할 수 있는 웹 검색 도구입니다.\n",
    "import langchain_community.tools.ddg_search\n",
    "\n",
    "# duckduckgo 검색 tool의 속성을 확인하여 검색 기능 호출 방법을 알아봅시다.\n",
    "print(dir(langchain_community.tools.ddg_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bdf73f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 확인한 duckduckgo의 검색 기능을 import합니다.\n",
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "\n",
    "# 검색 tool 인스턴스를 생성합니다.\n",
    "ddg_search_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f578afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 번째 방법을 배우기 전에, 위에서 만든 두 가지 tool을 Agent에게 전달해봅시다.\n",
    "# nano 모델은 Agent로 사용하기엔 너무 성능이 낮아 무한 루프 등 의도하지 않은 동작이 발생할 수 있으므로 mini 모델로 변경하겠습니다.\n",
    "model = init_chat_model(\"openai:gpt-5-mini\")\n",
    "\n",
    "# agent 생성 및 tool 전달\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[calculator, ddg_search_tool], # 앞서 만든 두 가지 tool을 리스트로 전달합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e75fd6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='2 더하기 3은 얼마야? 그리고 오늘 서울 날씨는 어때?', additional_kwargs={}, response_metadata={}, id='7c89a7b8-d2e0-4f29-8066-bf4851cdde2d'),\n",
      "              AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 221, 'prompt_tokens': 207, 'total_tokens': 428, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYmzk4w5zyoHmLczWsTqQT8Bh0fhj', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--7e4614bd-7538-46e2-ad18-0ad10938bd11-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': '서울 날씨 오늘'}, 'id': 'call_TJbqkIVMvntINp0KNR0a5U4k', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 221, 'total_tokens': 428, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}),\n",
      "              ToolMessage(content=\"현재 기온, 자외선 지수, 기압부터 풍속과 풍향까지, korea247.kr 의 전문가들이 서울특별시 의 기상 상태를 명확하고 실시간으로, 그리고 유용하게 전달해 드리며, 전반적인 날씨 상황을 파악할 수 있도록 돕습니다. 이투데이 날씨 오늘날씨 ... [내일날씨] 출근길 짙은 안개 주의…낮 최고기온 22도 '포근' [날씨] 아침 쌀쌀·낮엔 포근…15도 안팎 일교차 주의 2025.11. ... The Weather Channel 및 Weather.com이 제공하는 오늘과 오늘 밤 서울특별시 일기예보, 날씨 상태 및 도플러 레이더 Check current conditions in 서울특별시, 서울시, 대한민국 with radar, hourly, and more. MSN 날씨과 (와) 함께 Seoul-Jikhalsi, 서울특별시의 오늘, 오늘 밤, 내일에 대한 정확한 시간별 예보와 함께 10일간의 일일 예보 및 기상 레이더를 확인하세요. 강수량, 악천후 경보, 대기질 및 …\", name='duckduckgo_search', id='ab0f67f3-6d4e-42bd-80b2-f14bbaf415f3', tool_call_id='call_TJbqkIVMvntINp0KNR0a5U4k'),\n",
      "              AIMessage(content='2 더하기 3은 5입니다.\\n\\n오늘 서울 날씨는(검색 결과 기준) 아침에 짙은 안개로 쌀쌀하고, 낮에는 포근해 낮 최고 기온이 대략 20–22°C 정도로 예보되어 있습니다. 다만 저는 실시간 관측소에 직접 연결되어 있지 않아 현재 기온·강수 여부·미세먼지 등 세부 정보는 바로 확인해 드리기 어렵습니다. 원하시면 지금 정확한 현재 기온·시간별 예보·미세먼지 등을 바로 찾아서 알려드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 841, 'prompt_tokens': 507, 'total_tokens': 1348, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 704, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYmzrH5pQSvvdc6O7mqZA42XP6ZPF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d6e44498-9764-446c-8b8c-4715f9ff892d-0', usage_metadata={'input_tokens': 507, 'output_tokens': 841, 'total_tokens': 1348, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 704}})]}\n"
     ]
    }
   ],
   "source": [
    "# Agent에 전달할 메시지 객체를 생성하기 위해 필요한 모듈입니다.\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "# Agent에 전달할 메시지 객체를 생성합니다.\n",
    "messages = [\n",
    "    HumanMessage(content=\"2 더하기 3은 얼마야? 그리고 오늘 서울 날씨는 어때?\"),\n",
    "]\n",
    "\n",
    "# Agent에 대한 invoke는 모델 invoke와는 다르게 dictionary 형태의 입력을 받으니 주의하세요.\n",
    "response = agent.invoke({\"messages\":messages})\n",
    "\n",
    "\n",
    "# Agent가 보내준 전체 응답에는 추론 과정과 tool 사용 내역이 포함되어 있습니다.\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4192ca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2 더하기 3은 5입니다.\\n'\n",
      " '\\n'\n",
      " '오늘 서울 날씨는(검색 결과 기준) 아침에 짙은 안개로 쌀쌀하고, 낮에는 포근해 낮 최고 기온이 대략 20–22°C 정도로 예보되어 '\n",
      " '있습니다. 다만 저는 실시간 관측소에 직접 연결되어 있지 않아 현재 기온·강수 여부·미세먼지 등 세부 정보는 바로 확인해 드리기 '\n",
      " '어렵습니다. 원하시면 지금 정확한 현재 기온·시간별 예보·미세먼지 등을 바로 찾아서 알려드릴까요?')\n"
     ]
    }
   ],
   "source": [
    "# 실제 답변 내용만 출력하려면 messages 리스트의 마지막 요소의 content 속성을 참조합니다.\n",
    "pprint(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099846f4",
   "metadata": {},
   "source": [
    "### 4-3. 모델 vendor들이 제공하는 tool을 모델에 바인딩\n",
    "\n",
    "#### **※ 주의!! ※**\n",
    "- 현재 버전에서 Agent를 통하지 않고 단일 Model을 직접 호출해야만 사용할 수 있는 기능입니다.\n",
    "- Agent를 활용하는 경우 사용할 수 없는 방법이므로 헷갈리지 마세요!\n",
    "- 설계가 복잡해지고 세밀한 구조 설계, 유지보수를 어렵게 만드는 방식이니 사용하지 마세요.\n",
    "- 다만, 이 방법을 아예 모르고 있으면 GPT나 Docs 보고 코드 쓰다가 tool 정의 및 호출 방법을 섞어서 쓰다가 코드가 꼬일 수 있기 때문에 개념만 이해하고 넘어갑시다.\n",
    "---\n",
    "#### 실습\n",
    "- LLM API를 제공하는 vendor들은 모델에서 곧바로 이용할 수 있는 tool을 함께 서비스하고 있습니다.\n",
    "- 예를 들어, OpenAI의 경우 웹 서치, MCP 서버 연결, 벡터 스토어 검색, 코드 실행 등의 도구를 제공합니다.\n",
    "- vendor가 제공하는 tool을 Agent에 바인딩하여 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1e410ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[답변]: content='대한민국의 수도는 서울특별시(서울)입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 151, 'prompt_tokens': 15, 'total_tokens': 166, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYn07e7EYdAtkzLHmJUMmITUrsY32', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--5f18f1b3-bd1f-437d-bacb-8dea1715d81d-0' usage_metadata={'input_tokens': 15, 'output_tokens': 151, 'total_tokens': 166, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.5,\n",
    "    model_name=\"gpt-5-mini\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질의내용\n",
    "question = \"대한민국의 수도는 어디인가요?\"\n",
    "\n",
    "# 질의\n",
    "print(f\"[답변]: {llm.invoke(question)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "958d2115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content=[{'id': 'rs_0437b43581507ac900690c3480f78081928bc741b5650ab945', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0437b43581507ac900690c348284c48192bc16ce416ba34b2b', 'action': {'query': 'South Korea November 2025 movie releases November 2025 release schedule Korea major films', 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0437b43581507ac900690c348514148192af14e80d3c98d748', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0437b43581507ac900690c34858ba08192aa755889d59189b8', 'action': {'query': \"2025년 11월 개봉 영화 한국 11월 개봉작 2025 '개봉' '11월' '한국' '영화' '2025' \", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0437b43581507ac900690c34870cc88192adac08bcb9049605', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0437b43581507ac900690c34892d5c8192b0eff089791945f7', 'action': {'query': \"위키드: 포 굿 2025 한국 개봉일 11월 19일 CGV '위키드 2' '개봉' '한국' '11월' '2025' \", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0437b43581507ac900690c348b11a081929a9dc166977d6b06', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0437b43581507ac900690c348ddfb88192a8214e2a724464a0', 'action': {'query': \"글래디에이터 2 한국 개봉일 'Gladiator II' Korea release date 2025 '글래디에이터 II' 개봉일\", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0437b43581507ac900690c348f81e88192abc6f0479ae5a065', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0437b43581507ac900690c3492d7c88192acb622fb5afd986c', 'action': {'query': \"모아나 2 한국 개봉일 2025 '모아나 2' 개봉 '한국' '2025' '개봉일' \", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0437b43581507ac900690c34966a8881928a8b666410383dcd', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0437b43581507ac900690c3499e8f881928ea2f0115836be07', 'action': {'query': \"한란 2025 개봉일 김향기 '한란' 11월 26일 개봉\", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0437b43581507ac900690c349c1ad08192adeb9bd67c2ca83e', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0437b43581507ac900690c349cf0988192bd7b27565c44e067', 'action': {'query': \"한란 김향기 2025 개봉일 '한란' 11월 26일 개봉 '영화 한란' '김향기' '개봉' \", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0437b43581507ac900690c349eeac08192b7bf4eeabbe19c84', 'summary': [], 'type': 'reasoning'}, {'arguments': '{\"num_1\":12311,\"num_2\":112455}', 'call_id': 'call_5ru5cli0AIk6eq8netIAwFK8', 'name': 'calculator', 'type': 'function_call', 'id': 'fc_0437b43581507ac900690c34a302948192855590c983dadb64', 'status': 'completed'}], additional_kwargs={}, response_metadata={'id': 'resp_0437b43581507ac900690c34806a04819288e7b6f555e7cbf2', 'created_at': 1762407552.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0437b43581507ac900690c34806a04819288e7b6f555e7cbf2', tool_calls=[{'name': 'calculator', 'args': {'num_1': 12311, 'num_2': 112455}, 'id': 'call_5ru5cli0AIk6eq8netIAwFK8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 32048, 'output_tokens': 1630, 'total_tokens': 33678, 'input_token_details': {'cache_read': 4480}, 'output_token_details': {'reasoning': 1600}})\n"
     ]
    }
   ],
   "source": [
    "# 모델 vendor들이 제공하는 tool을 모델에 바인딩하기 위해 필요한 모듈입니다.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI 전용 Model 초기화 메서드입니다.\n",
    "# OpenAI 모델에서 제공하는 tool을 바인딩하기 위해서는 모델 초기화시 ChatOpenAI 클래스를 사용해야 합니다.\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-5-mini\",\n",
    ")\n",
    "\n",
    "# ChatOpenAI 모델 인스턴스에 커스텀 tool을 바인딩합니다.\n",
    "\n",
    "\n",
    "# 모델이 사용할 tool 리스트를 정의합니다.\n",
    "# 딕셔너리 형태의 web search tool은 openai가 제공하는 tool이고, calculator는 위에서 직접 만든 커스텀 tool입니다.\n",
    "# ddg는 웹 검색 역할이 중복되므로 제외합니다.\n",
    "tools = [{\"type\": \"web_search\"}, calculator]\n",
    "\n",
    "model_with_calculator = model.bind_tools(tools) \n",
    "\n",
    "# model을 호출합니다.\n",
    "response = model_with_calculator.invoke(\n",
    "    \"올해 11월에 한국에서 개봉하는 주요 영화 3개만 알려줘. 그리고 12311 더하기 112455는 몇이야?\",\n",
    ")\n",
    "\n",
    "# 추론 과정에서 커스텀 tool이 호출되면, 추론 루프를 멈추고 AIMessage를 반환합니다.\n",
    "# Agent가 아닌 단일 모델에 대한 invoke이기 때문에 커스텀 tool 호출에는 대응하지 못하기 때문입니다.\n",
    "# 별도로 다시 invoke를 체이닝하는 등 추가 코드가 필요하나, 너무 구린 방식이니까 그냥 넘어가겠습니다.\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806767b",
   "metadata": {},
   "source": [
    "## 5. 메모리\n",
    "\n",
    "- 맥락을 유지하고 개인화된 응답을 제공하기 위해 checkpointer 객체에 메모리를 저장합니다.\n",
    "- 스레드 내에서만 유지할 메모리와 DB에 저장할 메모리를 구분하여 메모리 객체를 생성해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c0697",
   "metadata": {},
   "source": [
    "#### 5-1. 단기 메모리\n",
    "\n",
    "- 세션이 유지되는 동안 대화 기록을 저장해보겠습니다.\n",
    "- 세션이 종료되면 이 기억은 사라지며, 복구할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "22b96332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쓰레드 내 단기 기억 저장용 객체를 생성하기 위한 모듈입니다.\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# InMemorySaver 객체를 포함하여 Agent 생성\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[calculator, ddg_search_tool], # 앞서 만든 두 가지 tool을 리스트로 전달합니다.\n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b1b4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent에 전달할 메시지 객체를 생성하기 위해 필요한 모듈입니다.\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "# Agent에 전달할 메시지 객체를 생성합니다.\n",
    "messages = [\n",
    "    HumanMessage(content=\"한국에서 가볼 만한 여행지 추천해줘.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "020bdbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='한국에서 가볼 만한 여행지 추천해줘.', additional_kwargs={}, response_metadata={}, id='e0f94761-a122-4d8a-a07c-2eb307df4b2b'),\n",
      "              AIMessage(content='좋아요 — 여행 스타일이나 기간을 알려주시면 더 맞춤형으로 추천해드릴게요. 우선 인기 있고 매력적인 한국 여행지를 목적별·기간별로 간단히 정리해 드립니다.\\n\\n추천 여행지(하이라이트 + 권장 일정)\\n- 서울 — 경복궁·북촌·인사동(전통), 홍대·이태원·강남(젊음·쇼핑·밤문화), 남산·한강(전경/산책). 1~3일.\\n- 부산 — 해운대·광안리(해변), 감천문화마을(포토스팟), 자갈치시장(해산물). 1~2일(주말 추천).\\n- 제주도 — 한라산 등반, 성산일출봉, 만장굴, 협재·함덕 해변, 올레길 걷기. 3~5일.\\n- 경주 — 불국사·석굴암·첨성대·안압지 등 신라 역사 투어. 1~2일.\\n- 전주 — 전주한옥마을, 한옥 숙박, 비빔밥·전통한식 맛집. 1일(미식·문화).\\n- 강원도(설악산/강릉/속초) — 설악산 단풍/등산, 동해 해변, 커피거리(강릉). 1~3일(계절 활동 다양).\\n- 안동(하회마을) — 전통 민속마을과 문화체험. 1일.\\n- 보성·남해·순천 — 보성 녹차밭, 순천만 습지, 남해의 풍경·드라이브 코스. 1~2일.\\n- 담양 — 메타세쿼이아 길, 죽녹원(여유로운 자연). 1일.\\n- DMZ(비무장지대) 투어 — 역사·안보 관람(사전 예약 필요). 반나절~1일.\\n- 평창·강릉(겨울스포츠) — 스키·스노보드(겨울). 1~3일.\\n- 부산 근교/경남(거제·통영) — 한려수도 풍경, 섬 투어, 해산물. 1~2일.\\n\\n테마별 추천\\n- 자연·트레킹: 제주도(한라산), 설악산, 지리산\\n- 해변·휴양: 제주, 부산(해운대), 강릉\\n- 역사·문화: 경주, 전주, 안동\\n- 음식여행: 광주·전주(전통 한식), 부산(해산물), 서울(다양한 전문 맛집)\\n- 사진·감성: 감천문화마을, 북촌, 보성녹차밭, 남해\\n\\n이동 팁\\n- 장거리: KTX(서울↔부산/경주/전주 등) 추천. 제주도는 항공/배편.\\n- 지역 내: 시내버스·택시가 잘 발달. 관광지 셔틀·투어도 많음.\\n\\n계절별 추천\\n- 봄: 벚꽃(경주·진해·서울 여의도), 온화한 날씨\\n- 여름: 해변(제주·부산·강릉)\\n- 가을: 단풍(설악산·내장산·한라산), 선선한 날씨\\n- 겨울: 스키·스노보드(평창, 강원권), 제주 온화\\n\\n간단한 문화 팁\\n- 실내(집·전통식당)에서는 신발 벗기 일반적.\\n- 팁 문화는 보편적이지 않음(특정 고급 호텔 제외).\\n- 관광지·맛집은 주말에 붐빔 — 가능하면 평일 이용 추천.\\n\\n원하시면:\\n- 여행 기간(예: 주말/3일/일주일), 예산, 함께 가는 사람(혼자/커플/가족), 선호(자연/먹방/문화/액티비티)을 알려주세요. 그에 맞춰 상세 일정과 교통·숙소 추천까지 만들어 드릴게요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1265, 'prompt_tokens': 201, 'total_tokens': 1466, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYn0mKIdRW36jl2ZZ6BX0reN3YGjw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--7e47b6c6-f7bf-494c-8e04-857a249fe5c1-0', usage_metadata={'input_tokens': 201, 'output_tokens': 1265, 'total_tokens': 1466, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}})]}\n"
     ]
    }
   ],
   "source": [
    "# Agent 호출\n",
    "# Agent에 대한 invoke는 모델 invoke와는 다르게 dictionary 형태의 입력을 받으니 주의하세요.\n",
    "response = agent.invoke(\n",
    "    {\"messages\":messages},\n",
    "    # 설정값으로 대화 기록을 저장할 쓰레드 번호를 함께 넘겨줘야 합니다.\n",
    "    # 대화 기록이 들어 있는 쓰레드는 세션 종료시 삭제됩니다.\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    )\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a3a94b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('좋아요 — 여행 스타일이나 기간을 알려주시면 더 맞춤형으로 추천해드릴게요. 우선 인기 있고 매력적인 한국 여행지를 목적별·기간별로 간단히 '\n",
      " '정리해 드립니다.\\n'\n",
      " '\\n'\n",
      " '추천 여행지(하이라이트 + 권장 일정)\\n'\n",
      " '- 서울 — 경복궁·북촌·인사동(전통), 홍대·이태원·강남(젊음·쇼핑·밤문화), 남산·한강(전경/산책). 1~3일.\\n'\n",
      " '- 부산 — 해운대·광안리(해변), 감천문화마을(포토스팟), 자갈치시장(해산물). 1~2일(주말 추천).\\n'\n",
      " '- 제주도 — 한라산 등반, 성산일출봉, 만장굴, 협재·함덕 해변, 올레길 걷기. 3~5일.\\n'\n",
      " '- 경주 — 불국사·석굴암·첨성대·안압지 등 신라 역사 투어. 1~2일.\\n'\n",
      " '- 전주 — 전주한옥마을, 한옥 숙박, 비빔밥·전통한식 맛집. 1일(미식·문화).\\n'\n",
      " '- 강원도(설악산/강릉/속초) — 설악산 단풍/등산, 동해 해변, 커피거리(강릉). 1~3일(계절 활동 다양).\\n'\n",
      " '- 안동(하회마을) — 전통 민속마을과 문화체험. 1일.\\n'\n",
      " '- 보성·남해·순천 — 보성 녹차밭, 순천만 습지, 남해의 풍경·드라이브 코스. 1~2일.\\n'\n",
      " '- 담양 — 메타세쿼이아 길, 죽녹원(여유로운 자연). 1일.\\n'\n",
      " '- DMZ(비무장지대) 투어 — 역사·안보 관람(사전 예약 필요). 반나절~1일.\\n'\n",
      " '- 평창·강릉(겨울스포츠) — 스키·스노보드(겨울). 1~3일.\\n'\n",
      " '- 부산 근교/경남(거제·통영) — 한려수도 풍경, 섬 투어, 해산물. 1~2일.\\n'\n",
      " '\\n'\n",
      " '테마별 추천\\n'\n",
      " '- 자연·트레킹: 제주도(한라산), 설악산, 지리산\\n'\n",
      " '- 해변·휴양: 제주, 부산(해운대), 강릉\\n'\n",
      " '- 역사·문화: 경주, 전주, 안동\\n'\n",
      " '- 음식여행: 광주·전주(전통 한식), 부산(해산물), 서울(다양한 전문 맛집)\\n'\n",
      " '- 사진·감성: 감천문화마을, 북촌, 보성녹차밭, 남해\\n'\n",
      " '\\n'\n",
      " '이동 팁\\n'\n",
      " '- 장거리: KTX(서울↔부산/경주/전주 등) 추천. 제주도는 항공/배편.\\n'\n",
      " '- 지역 내: 시내버스·택시가 잘 발달. 관광지 셔틀·투어도 많음.\\n'\n",
      " '\\n'\n",
      " '계절별 추천\\n'\n",
      " '- 봄: 벚꽃(경주·진해·서울 여의도), 온화한 날씨\\n'\n",
      " '- 여름: 해변(제주·부산·강릉)\\n'\n",
      " '- 가을: 단풍(설악산·내장산·한라산), 선선한 날씨\\n'\n",
      " '- 겨울: 스키·스노보드(평창, 강원권), 제주 온화\\n'\n",
      " '\\n'\n",
      " '간단한 문화 팁\\n'\n",
      " '- 실내(집·전통식당)에서는 신발 벗기 일반적.\\n'\n",
      " '- 팁 문화는 보편적이지 않음(특정 고급 호텔 제외).\\n'\n",
      " '- 관광지·맛집은 주말에 붐빔 — 가능하면 평일 이용 추천.\\n'\n",
      " '\\n'\n",
      " '원하시면:\\n'\n",
      " '- 여행 기간(예: 주말/3일/일주일), 예산, 함께 가는 사람(혼자/커플/가족), 선호(자연/먹방/문화/액티비티)을 알려주세요. 그에 '\n",
      " '맞춰 상세 일정과 교통·숙소 추천까지 만들어 드릴게요.')\n"
     ]
    }
   ],
   "source": [
    "# 실제 답변 내용만 출력하려면 messages 리스트의 마지막 요소의 content 속성을 참조합니다.\n",
    "pprint(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "62894c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='한국에서 가볼 만한 여행지 추천해줘.', additional_kwargs={}, response_metadata={}, id='e0f94761-a122-4d8a-a07c-2eb307df4b2b'),\n",
      "              AIMessage(content='좋아요 — 여행 스타일이나 기간을 알려주시면 더 맞춤형으로 추천해드릴게요. 우선 인기 있고 매력적인 한국 여행지를 목적별·기간별로 간단히 정리해 드립니다.\\n\\n추천 여행지(하이라이트 + 권장 일정)\\n- 서울 — 경복궁·북촌·인사동(전통), 홍대·이태원·강남(젊음·쇼핑·밤문화), 남산·한강(전경/산책). 1~3일.\\n- 부산 — 해운대·광안리(해변), 감천문화마을(포토스팟), 자갈치시장(해산물). 1~2일(주말 추천).\\n- 제주도 — 한라산 등반, 성산일출봉, 만장굴, 협재·함덕 해변, 올레길 걷기. 3~5일.\\n- 경주 — 불국사·석굴암·첨성대·안압지 등 신라 역사 투어. 1~2일.\\n- 전주 — 전주한옥마을, 한옥 숙박, 비빔밥·전통한식 맛집. 1일(미식·문화).\\n- 강원도(설악산/강릉/속초) — 설악산 단풍/등산, 동해 해변, 커피거리(강릉). 1~3일(계절 활동 다양).\\n- 안동(하회마을) — 전통 민속마을과 문화체험. 1일.\\n- 보성·남해·순천 — 보성 녹차밭, 순천만 습지, 남해의 풍경·드라이브 코스. 1~2일.\\n- 담양 — 메타세쿼이아 길, 죽녹원(여유로운 자연). 1일.\\n- DMZ(비무장지대) 투어 — 역사·안보 관람(사전 예약 필요). 반나절~1일.\\n- 평창·강릉(겨울스포츠) — 스키·스노보드(겨울). 1~3일.\\n- 부산 근교/경남(거제·통영) — 한려수도 풍경, 섬 투어, 해산물. 1~2일.\\n\\n테마별 추천\\n- 자연·트레킹: 제주도(한라산), 설악산, 지리산\\n- 해변·휴양: 제주, 부산(해운대), 강릉\\n- 역사·문화: 경주, 전주, 안동\\n- 음식여행: 광주·전주(전통 한식), 부산(해산물), 서울(다양한 전문 맛집)\\n- 사진·감성: 감천문화마을, 북촌, 보성녹차밭, 남해\\n\\n이동 팁\\n- 장거리: KTX(서울↔부산/경주/전주 등) 추천. 제주도는 항공/배편.\\n- 지역 내: 시내버스·택시가 잘 발달. 관광지 셔틀·투어도 많음.\\n\\n계절별 추천\\n- 봄: 벚꽃(경주·진해·서울 여의도), 온화한 날씨\\n- 여름: 해변(제주·부산·강릉)\\n- 가을: 단풍(설악산·내장산·한라산), 선선한 날씨\\n- 겨울: 스키·스노보드(평창, 강원권), 제주 온화\\n\\n간단한 문화 팁\\n- 실내(집·전통식당)에서는 신발 벗기 일반적.\\n- 팁 문화는 보편적이지 않음(특정 고급 호텔 제외).\\n- 관광지·맛집은 주말에 붐빔 — 가능하면 평일 이용 추천.\\n\\n원하시면:\\n- 여행 기간(예: 주말/3일/일주일), 예산, 함께 가는 사람(혼자/커플/가족), 선호(자연/먹방/문화/액티비티)을 알려주세요. 그에 맞춰 상세 일정과 교통·숙소 추천까지 만들어 드릴게요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1265, 'prompt_tokens': 201, 'total_tokens': 1466, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYn0mKIdRW36jl2ZZ6BX0reN3YGjw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--7e47b6c6-f7bf-494c-8e04-857a249fe5c1-0', usage_metadata={'input_tokens': 201, 'output_tokens': 1265, 'total_tokens': 1466, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}}),\n",
      "              HumanMessage(content='서울 안에서는?', additional_kwargs={}, response_metadata={}, id='52ba7818-d022-413f-941b-27d4c6aa6356'),\n",
      "              AIMessage(content='좋아요 — 서울 안에서 할 만한 것들을 목적별·지역별로 정리해드릴게요. 원하시면 이 중에서 일정(하루/이틀)로 바로 짜드릴게요.\\n\\n주요 지역별 하이라이트\\n- 경복궁·북촌·인사동(종로)\\n  - 전통 궁궐(경복궁, 창덕궁+후원 예약 권장), 한옥 골목(북촌), 전통차·공예(인사동).\\n  - 팁: 한복 착용 시 주요 궁궐 무료 입장 가능(체크 필요).\\n- 명동·남대문·명동성당\\n  - 화장품·패션 쇼핑, 거리 음식, 외국인 관광객 많은 지역.\\n- 동대문·DDP\\n  - 패션 도매상가, 밤샘 쇼핑, 디자인 전시(DDP).\\n- 홍대·합정·연남\\n  - 젊음의 거리, 인디음악·카페·클럽, 스트리트 퍼포먼스, 개성 있는 식당·플리마켓.\\n- 이태원·한남·경리단길\\n  - 글로벌 음식, 바·나이트라이프, 외국 문화가 공존하는 동네.\\n- 강남·청담·압구정\\n  - 럭셔리 쇼핑, 트렌디 카페·레스토랑, 코엑스(쇼핑몰·아쿠아리움·별마당도서관).\\n- 성수·왕십리\\n  - 카페·디자인 스튜디오·공장 리노베이션 스폿(성수동 수제화 거리).\\n- 잠실·석촌호수·롯데월드타워\\n  - 전망대, 쇼핑몰, 롯데월드(실내·실외 놀이공원), 석촌호수 산책.\\n- 한강 공원(여의도·반포·잠원 등)\\n  - 자전거·피크닉·유람선·야경(반포대교 분수).\\n- 광장시장·남대문·노량진·노포 골목\\n  - 재래시장·전통 먹거리(빈대떡·육회·회·해산물).\\n\\n테마별 추천 활동\\n- 역사·전통: 경복궁(수문장 교대), 창덕궁 후원, 국립민속박물관, 북촌 산책\\n- 예술·박물관: 국립중앙박물관, MMCA(국립현대미술관 서울관), 리움미술관, DDP 전시\\n- 쇼핑·트렌드: 명동·동대문·가로수길·코엑스·성수\\n- 먹방·재래시장: 광장시장(마약김밥, 빈대떡), 통인시장(도시락카페), 노량진시장(회)\\n- 휴식·야경: N서울타워(남산), 반포대교(무지개분수), 한강 공원에서 피크닉\\n- 가족·어린이: 롯데월드·서울랜드·키즈카페·서울어린이대공원\\n- 체험: 찜질방(스파), 한복 대여, 쿠킹 클래스, K-POP 관련 공연·뮤지컬\\n\\n추천 1일 코스 예시\\n- 전통 코스 (종로/경복궁)\\n  - 오전: 경복궁·수문장 교대 관람 → 국립민속박물관\\n  - 점심: 인사동·북촌에서 전통 한식\\n  - 오후: 북촌 한옥마을 산책 → 인사동 공예품 쇼핑\\n  - 저녁: 종로 주변 전통주·한식 바\\n- 트렌디&카페 코스 (성수·압구정)\\n  - 오전: 성수동 카페·플랫폼 창동(또는 성수 수제화 거리)\\n  - 점심: 성수 맛집\\n  - 오후: 압구정/가로수길 쇼핑\\n  - 저녁: 한강 또는 강남 라운지 바\\n- 젊음·밤문화 코스 (홍대→이태원)\\n  - 오후: 홍대 거리·플리마켓·카페\\n  - 저녁: 홍대 클럽 혹은 이태원 바/다국적 음식\\n  - 늦은 밤: 해장국·분식으로 마무리\\n- 가족/아이와 (잠실·석촌)\\n  - 오전: 롯데월드(놀이기구/아쿠아리움)\\n  - 점심: 롯데몰 식당가\\n  - 오후: 석촌호수 산책 → 롯데타워 전망대\\n- 가성비 먹방 코스\\n  - 오전: 광장시장(빈대떡·마약김밥)\\n  - 점심: 중구의 오래된 국숫집·칼국수\\n  - 오후: 망원시장 카페·거리 음식 투어\\n  - 저녁: 노량진에서 회 또는 노포에서 식사\\n\\n실용 팁\\n- 교통: 지하철·버스가 가장 편리. T-money 교통카드(충전식) 추천. 출퇴근(7:30-9:30, 17:00-19:00) 혼잡.\\n- 길찾기 앱: 카카오맵, 네이버지도(대중교통/도보길 안내 우수).\\n- 택시: 카카오T 앱 사용 편리. 영어 의사소통 어려울 수 있으니 목적지 주소(한글) 준비.\\n- 예약: 인기 맛집·전시·한강 유람선·창덕궁 후원 등은 사전 예약 권장.\\n- 날씨: 여름엔 더우니 한강 피크닉·야간 활동 추천, 겨울엔 따뜻한 옷과 실내 관광 위주.\\n- 안전: 대체로 안전하나 소지품 주의, 밤늦게 혼자 골목은 피하는 게 좋음.\\n- 언어: 관광지·주요 상점에서는 영어 통하지만 현지식당·시골 분들은 한국어 위주. 번역앱 활용.\\n\\n원하시면\\n- 일정(하루/주말/2~3일), 동행(혼자/커플/가족/아이), 관심사(먹방/사진/쇼핑/자연/역사) 알려주세요. 맞춤 1~2일 구체 일정(시간별), 교통 경로, 추천 식당까지 바로 만들어 드릴게요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2130, 'prompt_tokens': 1151, 'total_tokens': 3281, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYn195UGPftC4t4IqhT4sS3zE3u07', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d03f8cf0-a570-40a4-8118-686571306a5c-0', usage_metadata={'input_tokens': 1151, 'output_tokens': 2130, 'total_tokens': 3281, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 640}})]}\n"
     ]
    }
   ],
   "source": [
    "# LLM이 이전 대화 맥락을 잘 기억하는지 확인해봅시다.\n",
    "\n",
    "# Agent에 전달할 메시지 객체를 생성합니다.\n",
    "messages = [\n",
    "    HumanMessage(content=\"서울 안에서는?\"),\n",
    "]\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\":messages},\n",
    "    # 설정값으로 대화 기록을 저장할 쓰레드 번호를 함께 넘겨줘야 합니다.\n",
    "    # 대화 기록이 들어 있는 쓰레드는 세션 종료시 삭제됩니다.\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    )\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d1a45a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('좋아요 — 서울 안에서 할 만한 것들을 목적별·지역별로 정리해드릴게요. 원하시면 이 중에서 일정(하루/이틀)로 바로 짜드릴게요.\\n'\n",
      " '\\n'\n",
      " '주요 지역별 하이라이트\\n'\n",
      " '- 경복궁·북촌·인사동(종로)\\n'\n",
      " '  - 전통 궁궐(경복궁, 창덕궁+후원 예약 권장), 한옥 골목(북촌), 전통차·공예(인사동).\\n'\n",
      " '  - 팁: 한복 착용 시 주요 궁궐 무료 입장 가능(체크 필요).\\n'\n",
      " '- 명동·남대문·명동성당\\n'\n",
      " '  - 화장품·패션 쇼핑, 거리 음식, 외국인 관광객 많은 지역.\\n'\n",
      " '- 동대문·DDP\\n'\n",
      " '  - 패션 도매상가, 밤샘 쇼핑, 디자인 전시(DDP).\\n'\n",
      " '- 홍대·합정·연남\\n'\n",
      " '  - 젊음의 거리, 인디음악·카페·클럽, 스트리트 퍼포먼스, 개성 있는 식당·플리마켓.\\n'\n",
      " '- 이태원·한남·경리단길\\n'\n",
      " '  - 글로벌 음식, 바·나이트라이프, 외국 문화가 공존하는 동네.\\n'\n",
      " '- 강남·청담·압구정\\n'\n",
      " '  - 럭셔리 쇼핑, 트렌디 카페·레스토랑, 코엑스(쇼핑몰·아쿠아리움·별마당도서관).\\n'\n",
      " '- 성수·왕십리\\n'\n",
      " '  - 카페·디자인 스튜디오·공장 리노베이션 스폿(성수동 수제화 거리).\\n'\n",
      " '- 잠실·석촌호수·롯데월드타워\\n'\n",
      " '  - 전망대, 쇼핑몰, 롯데월드(실내·실외 놀이공원), 석촌호수 산책.\\n'\n",
      " '- 한강 공원(여의도·반포·잠원 등)\\n'\n",
      " '  - 자전거·피크닉·유람선·야경(반포대교 분수).\\n'\n",
      " '- 광장시장·남대문·노량진·노포 골목\\n'\n",
      " '  - 재래시장·전통 먹거리(빈대떡·육회·회·해산물).\\n'\n",
      " '\\n'\n",
      " '테마별 추천 활동\\n'\n",
      " '- 역사·전통: 경복궁(수문장 교대), 창덕궁 후원, 국립민속박물관, 북촌 산책\\n'\n",
      " '- 예술·박물관: 국립중앙박물관, MMCA(국립현대미술관 서울관), 리움미술관, DDP 전시\\n'\n",
      " '- 쇼핑·트렌드: 명동·동대문·가로수길·코엑스·성수\\n'\n",
      " '- 먹방·재래시장: 광장시장(마약김밥, 빈대떡), 통인시장(도시락카페), 노량진시장(회)\\n'\n",
      " '- 휴식·야경: N서울타워(남산), 반포대교(무지개분수), 한강 공원에서 피크닉\\n'\n",
      " '- 가족·어린이: 롯데월드·서울랜드·키즈카페·서울어린이대공원\\n'\n",
      " '- 체험: 찜질방(스파), 한복 대여, 쿠킹 클래스, K-POP 관련 공연·뮤지컬\\n'\n",
      " '\\n'\n",
      " '추천 1일 코스 예시\\n'\n",
      " '- 전통 코스 (종로/경복궁)\\n'\n",
      " '  - 오전: 경복궁·수문장 교대 관람 → 국립민속박물관\\n'\n",
      " '  - 점심: 인사동·북촌에서 전통 한식\\n'\n",
      " '  - 오후: 북촌 한옥마을 산책 → 인사동 공예품 쇼핑\\n'\n",
      " '  - 저녁: 종로 주변 전통주·한식 바\\n'\n",
      " '- 트렌디&카페 코스 (성수·압구정)\\n'\n",
      " '  - 오전: 성수동 카페·플랫폼 창동(또는 성수 수제화 거리)\\n'\n",
      " '  - 점심: 성수 맛집\\n'\n",
      " '  - 오후: 압구정/가로수길 쇼핑\\n'\n",
      " '  - 저녁: 한강 또는 강남 라운지 바\\n'\n",
      " '- 젊음·밤문화 코스 (홍대→이태원)\\n'\n",
      " '  - 오후: 홍대 거리·플리마켓·카페\\n'\n",
      " '  - 저녁: 홍대 클럽 혹은 이태원 바/다국적 음식\\n'\n",
      " '  - 늦은 밤: 해장국·분식으로 마무리\\n'\n",
      " '- 가족/아이와 (잠실·석촌)\\n'\n",
      " '  - 오전: 롯데월드(놀이기구/아쿠아리움)\\n'\n",
      " '  - 점심: 롯데몰 식당가\\n'\n",
      " '  - 오후: 석촌호수 산책 → 롯데타워 전망대\\n'\n",
      " '- 가성비 먹방 코스\\n'\n",
      " '  - 오전: 광장시장(빈대떡·마약김밥)\\n'\n",
      " '  - 점심: 중구의 오래된 국숫집·칼국수\\n'\n",
      " '  - 오후: 망원시장 카페·거리 음식 투어\\n'\n",
      " '  - 저녁: 노량진에서 회 또는 노포에서 식사\\n'\n",
      " '\\n'\n",
      " '실용 팁\\n'\n",
      " '- 교통: 지하철·버스가 가장 편리. T-money 교통카드(충전식) 추천. 출퇴근(7:30-9:30, 17:00-19:00) 혼잡.\\n'\n",
      " '- 길찾기 앱: 카카오맵, 네이버지도(대중교통/도보길 안내 우수).\\n'\n",
      " '- 택시: 카카오T 앱 사용 편리. 영어 의사소통 어려울 수 있으니 목적지 주소(한글) 준비.\\n'\n",
      " '- 예약: 인기 맛집·전시·한강 유람선·창덕궁 후원 등은 사전 예약 권장.\\n'\n",
      " '- 날씨: 여름엔 더우니 한강 피크닉·야간 활동 추천, 겨울엔 따뜻한 옷과 실내 관광 위주.\\n'\n",
      " '- 안전: 대체로 안전하나 소지품 주의, 밤늦게 혼자 골목은 피하는 게 좋음.\\n'\n",
      " '- 언어: 관광지·주요 상점에서는 영어 통하지만 현지식당·시골 분들은 한국어 위주. 번역앱 활용.\\n'\n",
      " '\\n'\n",
      " '원하시면\\n'\n",
      " '- 일정(하루/주말/2~3일), 동행(혼자/커플/가족/아이), 관심사(먹방/사진/쇼핑/자연/역사) 알려주세요. 맞춤 1~2일 구체 '\n",
      " '일정(시간별), 교통 경로, 추천 식당까지 바로 만들어 드릴게요.')\n"
     ]
    }
   ],
   "source": [
    "# 실제 답변 내용만 출력하려면 messages 리스트의 마지막 요소의 content 속성을 참조합니다.\n",
    "pprint(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8534b",
   "metadata": {},
   "source": [
    "### 5-2. 장기 메모리\n",
    "\n",
    "- 위에서 InMemorySaver로 만든 기억은 세션이 사라지면 함께 없어진다고 했습니다.\n",
    "- 사용자가 앱을 껐다 켜고, 기존에 대화를 나눴던 세션에 들어왔을 때도 기억이 남아있으려면, 대화 기록을 영속적으로 저장해야 합니다.\n",
    "- sqlite DB에 대화 기록을 저장할 수 있는 Agent를 만들어보겠습니다.\n",
    "- 다른 DB를 사용할 경우 해당 DB 관련 패키지 install 및 import가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "38660de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='서울 안에서는?', additional_kwargs={}, response_metadata={}, id='56162ef8-f25f-4675-932a-9bf25b330738'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690ad71452d8819e8ba8111b5c2caa0c', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '무엇에 대해 여쭤보신 건가요—좀 더 구체적으로 알려주실 수 있나요?\\n\\n가능한 의미 예시:\\n- 서울 안에서는 어디를 가볼까요? (관광·맛집 추천)\\n- 서울 안에서는 대중교통/택시 이용이 어떤가요?\\n- 서울 안에서는 배달/택배가 되나요?\\n- 서울 안에서는 코로나/방역 규칙은 어떤가요?\\n- 서울 안에서는 집값·월세는 어느 정도인가요?\\n- 서울 안에서는 주차 규정(혹은 자전거 관련) 어떻게 되나요?\\n\\n원하시는 항목이나 상세 조건(여행일정, 예산, 출발지 등)을 알려주시면 바로 도와드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ad719012c819eabfeea13ab32813c'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690ad713b084819e89a7449b838045ee', 'created_at': 1762318099.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690ad713b084819e89a7449b838045ee', usage_metadata={'input_tokens': 4481, 'output_tokens': 425, 'total_tokens': 4906, 'input_token_details': {'cache_read': 4352}, 'output_token_details': {'reasoning': 256}}),\n",
      "              HumanMessage(content='안녕?', additional_kwargs={}, response_metadata={}, id='94bac082-530f-4313-8b8e-2664f052a1d9'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690ad8f9809c819e8f43be7e22c372cd', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요? 이전에 쓰신 “서울 안에서는?” 관련해서\\n- 관광·맛집 추천\\n- 교통(지하철·버스·택시)\\n- 집값·월세 정보\\n- 배달·편의 서비스\\n- 방역·행사·날씨 등\\n\\n원하시는 항목과 날짜·예산·취향 같은 조건을 알려주시면 바로 도와드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ad8fce444819eb74f84e66cc7bd83'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690ad8f86d1c819ea45488b39283f6a3', 'created_at': 1762318584.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690ad8f86d1c819ea45488b39283f6a3', usage_metadata={'input_tokens': 4657, 'output_tokens': 301, 'total_tokens': 4958, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 192}}),\n",
      "              HumanMessage(content='안녕?', additional_kwargs={}, response_metadata={}, id='fc977b52-c249-4cea-aec3-343ed63bc207'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690ad97c341c819e8d0791ca949869f2', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요? 이전에 쓰신 “서울 안에서는?”과 관련해\\n- 관광·맛집 추천\\n- 교통(지하철·버스·택시)\\n- 숙박·집값·월세\\n- 배달·편의 서비스\\n- 행사·날씨·방역 등\\n\\n원하시는 항목이나 구체적인 질문을 알려주시면 바로 도와드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ad97e1f9c819eaf031e4dc4095fa7'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690ad97ba1ac819ebc196c163da7ce29', 'created_at': 1762318715.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690ad97ba1ac819ebc196c163da7ce29', usage_metadata={'input_tokens': 4771, 'output_tokens': 234, 'total_tokens': 5005, 'input_token_details': {'cache_read': 2432}, 'output_token_details': {'reasoning': 128}}),\n",
      "              HumanMessage(content='안녕?', additional_kwargs={}, response_metadata={}, id='daab4928-ad14-44d7-ab79-30eac5cdc863'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690ae420d050819e96475bc32ea0fa6c', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요?\\n\\n원하시는 게 있으면 알려주세요. 예: 서울 관련 정보(관광·교통·맛집), 일정짜기, 번역, 글쓰기, 아니면 그냥 수다 등. 한국어/영어 중 어떤 언어로 대화할지도 알려주시면 맞춰드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ae423cb9c819e98c97e3e1e82c0e7'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690ae41ee230819eaeedf9218261f619', 'created_at': 1762321439.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690ae41ee230819eaeedf9218261f619', usage_metadata={'input_tokens': 4886, 'output_tokens': 279, 'total_tokens': 5165, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 192}}),\n",
      "              HumanMessage(content='안녕?', additional_kwargs={}, response_metadata={}, id='06ef1a0b-a59b-40a0-aaf5-9ff90a6c93b0'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690ae4524f2c819ea62e337565bf7b78', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요?  \\n원하시는 게 있으면 말씀해 주세요. 예: 서울 정보(관광·맛집·교통), 일정짜기, 번역, 글쓰기, 아니면 그냥 수다도 좋아요. 어떤 언어로 대화할지도 알려주시면 맞춰드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ae45534fc819eb9db061affa3fef1'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690ae45196b4819eb6f589b05f01ea19', 'created_at': 1762321489.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690ae45196b4819eb6f589b05f01ea19', usage_metadata={'input_tokens': 4978, 'output_tokens': 212, 'total_tokens': 5190, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 128}}),\n",
      "              HumanMessage(content='안녕?', additional_kwargs={}, response_metadata={}, id='298da8ef-e9ce-4f45-9bb3-4773e4c51f07'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690ae49f79a0819eb5ce7266a6a8d6cf', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요?  \\n원하시는 걸 짧게 알려주시면 바로 시작할게요. (예: 서울 정보, 여행 일정, 번역, 글쓰기, 잡담 등)', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ae4a19e80819e87f46091ff69bb90'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690ae49e8790819eb73967d845342ce4', 'created_at': 1762321566.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690ae49e8790819eb73967d845342ce4', usage_metadata={'input_tokens': 5071, 'output_tokens': 186, 'total_tokens': 5257, 'input_token_details': {'cache_read': 4480}, 'output_token_details': {'reasoning': 128}}),\n",
      "              HumanMessage(content='안녕?', additional_kwargs={}, response_metadata={}, id='9898e7eb-40ce-4288-bbc2-5d5923578690'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690ae4a9efa0819ea374f5d0d79c7435', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 😊  \\n반가워요 — 어떻게 도와드릴까요?\\n\\n간단히 고르실래요?\\n- 수다/심심풀이\\n- 서울 추천(관광·맛집)\\n- 일정 짜기\\n- 번역·글쓰기 도움\\n- 퀴즈·간단한 게임\\n\\n원하시는 걸 한 단어만 써서 알려주시면 바로 시작할게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ae4aca550819e87dabe6eeaad537f'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690ae4a9244c819e86c6223263b7d9e6', 'created_at': 1762321577.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690ae4a9244c819e86c6223263b7d9e6', usage_metadata={'input_tokens': 5136, 'output_tokens': 288, 'total_tokens': 5424, 'input_token_details': {'cache_read': 4480}, 'output_token_details': {'reasoning': 192}}),\n",
      "              HumanMessage(content='안녕?', additional_kwargs={}, response_metadata={}, id='f9bbb70f-0647-4757-81bf-9d2373b28fc7'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690aebf47b44819e80db589a90ffd458', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 😊  \\n무엇을 도와드릴까요? 아래에서 하나 골라 숫자만 보내주셔도 돼요.\\n\\n1) 수다/심심풀이  \\n2) 퀴즈·간단한 게임  \\n3) 서울 정보(관광·맛집·교통)  \\n4) 번역·글쓰기 도움  \\n5) 장난스러운 인사나 농담 듣기\\n\\n원하시는 게 있으면 숫자나 한 단어로 말씀해 주세요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690aebf71ea4819ebe61384728c135c8'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690aebf31478819e929c03462e7a8400', 'created_at': 1762323443.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690aebf31478819e929c03462e7a8400', usage_metadata={'input_tokens': 5239, 'output_tokens': 245, 'total_tokens': 5484, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 128}}),\n",
      "              HumanMessage(content='안녕?', additional_kwargs={}, response_metadata={}, id='f090706d-07b9-435d-849b-00f0b469d694'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690c333391fc819eb82632f5eaf7879d', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 😊  \\n무엇을 도와드릴까요? 간단히 골라주세요—숫자나 한 단어로 알려주시면 바로 시작할게요.\\n\\n1) 수다  \\n2) 퀴즈/게임  \\n3) 서울 정보(관광·맛집·교통)  \\n4) 번역·글쓰기 도움  \\n5) 그냥 인사만', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690c3336e504819e959174f7d231071d'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690c3332fa94819ea90758d26e22a430', 'created_at': 1762407219.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690c3332fa94819ea90758d26e22a430', usage_metadata={'input_tokens': 5361, 'output_tokens': 348, 'total_tokens': 5709, 'input_token_details': {'cache_read': 2432}, 'output_token_details': {'reasoning': 256}}),\n",
      "              HumanMessage(content='langchain의 설계 철학에 대해 알려줘.', additional_kwargs={}, response_metadata={}, id='f28baf45-295f-42f9-bd29-6161d60e80d5'),\n",
      "              HumanMessage(content='langchain의 설계 철학에 대해 알려줘.', additional_kwargs={}, response_metadata={}, id='16517c28-1549-41fb-b8f2-1d3199ff11d1'),\n",
      "              HumanMessage(content='langchain의 설계 철학에 대해 알려줘.', additional_kwargs={}, response_metadata={}, id='3322bf75-96e6-43ae-9085-aa09d93a4b5c'),\n",
      "              HumanMessage(content='langchain의 설계 철학에 대해 알려줘.', additional_kwargs={}, response_metadata={}, id='de61541f-3095-4bf0-9662-0ec92fcd24d5'),\n",
      "              AIMessage(content=[{'id': 'rs_0fc6438b81b8efa700690c34e09e54819ea9050747c44c2c8c', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0fc6438b81b8efa700690c34e51e38819e9768279aa487b715', 'action': {'query': 'LangChain design philosophy', 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0fc6438b81b8efa700690c34e66ef8819e9639d181365d3a53', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0fc6438b81b8efa700690c34eb8e6c819e898bb555f3dd31ed', 'action': {'query': \"LangChain composability 'design' 'composable' LangChain docs\", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0fc6438b81b8efa700690c34edaaa8819ea7c67ef6f591cd76', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0fc6438b81b8efa700690c34f0c6e8819ea52fc1215d2d8590', 'action': {'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0fc6438b81b8efa700690c34f1f820819eb924af8b86c12f87', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0fc6438b81b8efa700690c34f46d5c819e8850a9b045dca855', 'action': {'query': \"LangChain retrieval augmented generation docs 'retriever' 'vector store' 'RAG' site:langchain.com\", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0fc6438b81b8efa700690c34f5ff6c819eac80529e162f8a00', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '짧히 요약하면, LangChain의 설계 철학은 “인터페이스 기반의 모듈성 + 조합성(컴포저블 파이프라인) + 제공자(모델/저장소) 불가지론 + 실전(프로덕션) 지원/관측성”에 있습니다. 아래에 핵심 아이디어와 그것이 코드/아키텍처에 어떻게 반영되는지 정리합니다.\\n\\n핵심 원칙\\n- 추상화(인터페이스) 중심: LLM, 임베딩, 벡터 스토어, 리트리버 등 핵심 컴포넌트는 공통 인터페이스로 정의되어 있어, 다른 구현(여러 모델·DB)을 쉽게 교체할 수 있습니다. 이로써 모델/서비스 교체에 따른 엔지니어링 비용을 줄입니다. ([python.langchain.com](https://python.langchain.com/v0.2/docs/concepts/?utm_source=openai))\\n\\n- 컴포지션(조합성): 작은 단위의 “Runnable/체인”을 파이프처럼 연결해 복잡한 워크플로를 구성하도록 설계했습니다(LCEL/ Runnable). 이 접근은 동기/비동기, 배치, 스트리밍 처리를 일관되게 지원하고 재사용성을 높입니다. ([python.langchain.com](https://python.langchain.com/docs/concepts/runnables/?utm_source=openai))\\n\\n- 명확한 역할 분리 — Chains vs Agents: 경로가 고정되어 있고 결정론적일 때는 Chain(하드코드된 순서)을 권장하고, 불확실하거나 도구(툴)를 동적으로 호출해야 할 때는 Agent(LLM이 다음 동작을 결정)를 사용하도록 구분되어 있습니다. 즉 “가능하면 deterministic chain, 필요시 agent”의 실용적 조언이 담겨 있습니다. ([python.langchain.com](https://python.langchain.com/v0.1/docs/modules/agents/concepts/?utm_source=openai))\\n\\n- 데이터 연동(특히 RAG)·상태: 문서 로더 → 텍스트 분할 → 임베딩 → 벡터 인덱스 → 리트리버 → LLM(생성)의 흐름을 표준화해 RAG(검색 보강 생성) 워크플로를 쉽게 만들 수 있게 했습니다. 또한 대화형 메모리(버퍼, 요약, 엔티티 등) 추상화를 제공해 상태 보존을 다룹니다. ([python.langchain.com](https://python.langchain.com/v0.2/docs/tutorials/rag/?utm_source=openai))\\n\\n- 관측성·운영성: 실행(trace), 콜백, 토큰·시간 측정 등 관측(디버깅·평가)을 염두에 둔 API와 LangSmith 같은 도구(트레이싱/평가/배포)와의 연계를 강조합니다. 제품화(배포·디버깅) 관점이 설계에 포함되어 있습니다. ([python.langchain.com](https://python.langchain.com/docs/concepts/lcel/?utm_source=openai))\\n\\n설계적 결과(개발자 경험 측면)\\n- 경량 코어 + 통합 패키지 구조: 핵심 추상만을 담은 경량 패키지와(예: core) 다양한 외부 통합을 별도 패키지로 분리해 의존성을 관리합니다. 이는 테스트·유지보수를 쉽게 합니다. ([python.langchain.com](https://python.langchain.com/v0.2/docs/concepts/?utm_source=openai))\\n- 선언적·재사용 가능한 구성: LCEL/Runnable 같은 선언적 구성으로 파이프라인을 정의하면 런타임 최적화(병렬화, 스트리밍 등)와 일관된 동작을 얻을 수 있습니다. ([python.langchain.com](https://python.langchain.com/docs/concepts/lcel/?utm_source=openai))\\n- 실무 권장(안내): 불필요한 에이전트 사용 지양(툴이 너무 많으면 잘못된 선택을 할 수 있음), 메모리·컨텍스트는 비용·위험(드리프트)을 고려해 신중히 사용하라는 실용적 가이드가 문서 전반에 걸쳐 제시됩니다. ([python.langchain.com](https://python.langchain.com/v0.1/docs/modules/agents/concepts/?utm_source=openai))\\n\\n짧은 결론\\n- LangChain은 LLM 애플리케이션을 “미리 설계된 블록(인터페이스)들을 조합”해 빠르게 구축·운영하도록 만드는 데 초점을 둔 프레임워크입니다. 개발 편의성(교체성·조합성)과 운영 편의성(관측성·배포)을 모두 고려한 실용적 설계 철학을 가지고 있습니다. ([github.com](https://github.com/langchain-ai/langchain))\\n\\n원하시면:\\n- 예시 코드(간단한 RAG 체인 또는 LCEL 기반 파이프라인)를 보여드릴게요.\\n- 또는 “Agent vs Chain” 을 실제 코드로 비교해 드릴까요?', 'annotations': [{'end_index': 383, 'start_index': 291, 'title': 'Conceptual guide | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.2/docs/concepts/?utm_source=openai'}, {'end_index': 616, 'start_index': 519, 'title': 'Runnable interface | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/docs/concepts/runnables/?utm_source=openai'}, {'end_index': 928, 'start_index': 821, 'title': 'Concepts | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.1/docs/modules/agents/concepts/?utm_source=openai'}, {'end_index': 1190, 'start_index': 1093, 'title': 'Build a Retrieval Augmented Generation (RAG) App | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.2/docs/tutorials/rag/?utm_source=openai'}, {'end_index': 1416, 'start_index': 1324, 'title': 'LangChain Expression Language (LCEL) | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/docs/concepts/lcel/?utm_source=openai'}, {'end_index': 1633, 'start_index': 1541, 'title': 'Conceptual guide | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.2/docs/concepts/?utm_source=openai'}, {'end_index': 1823, 'start_index': 1731, 'title': 'LangChain Expression Language (LCEL) | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/docs/concepts/lcel/?utm_source=openai'}, {'end_index': 2050, 'start_index': 1943, 'title': 'Concepts | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.1/docs/modules/agents/concepts/?utm_source=openai'}, {'end_index': 2261, 'start_index': 2204, 'title': 'GitHub - langchain-ai/langchain:  The platform for reliable agents.', 'type': 'url_citation', 'url': 'https://github.com/langchain-ai/langchain'}], 'id': 'msg_0fc6438b81b8efa700690c34ff57c0819e80adb2ca0089bf26'}], additional_kwargs={}, response_metadata={'id': 'resp_0fc6438b81b8efa700690c34dfe6c4819ebe374eface36eb93', 'created_at': 1762407647.0, 'metadata': {}, 'model': 'gpt-5-mini-2025-08-07', 'object': 'response', 'service_tier': 'default', 'status': 'completed', 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07'}, id='resp_0fc6438b81b8efa700690c34dfe6c4819ebe374eface36eb93', usage_metadata={'input_tokens': 22051, 'output_tokens': 2633, 'total_tokens': 24684, 'input_token_details': {'cache_read': 5248}, 'output_token_details': {'reasoning': 1536}})]}\n"
     ]
    }
   ],
   "source": [
    "# sqlite용 checkpointer 객체 생성을 위한 모듈입니다.\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# checkpointer 객체 생성\n",
    "checkpointer = SqliteSaver.from_conn_string(\"checkpoints.db\")\n",
    "\n",
    "# DB는 with문 안에서만 연결되어 있습니다.\n",
    "with SqliteSaver.from_conn_string(\"checkpoints.db\") as checkpointer:\n",
    "    # 테이블이 없을 경우 생성\n",
    "    checkpointer.setup()\n",
    "    # Agent 객체 생성\n",
    "    agent = create_agent(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        checkpointer=checkpointer,\n",
    "    )\n",
    "    # 실행 후, sqlite DB에 대화 기록이 잘 저장되었는지 확인해보세요.\n",
    "    # Agent에 전달할 메시지 객체를 생성합니다.\n",
    "    messages = [\n",
    "        HumanMessage(content=\"langchain의 설계 철학에 대해 알려줘.\"),\n",
    "    ]\n",
    "\n",
    "    # Agent invoke\n",
    "    response = agent.invoke(\n",
    "        {\"messages\":messages},\n",
    "        {\"configurable\": {\"thread_id\":1}},\n",
    "        )\n",
    "\n",
    "    # 출력\n",
    "    pprint(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c65a907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. [HUMAN] 서울 안에서는?\n",
      "\n",
      "02. [AI] [{'id': 'rs_0fc6438b81b8efa700690ad71452d8819e8ba8111b5c2caa0c', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '무엇에 대해 여쭤보신 건가요—좀 더 구체적으로 알려주실 수 있나요?\\n\\n가능한 의미 예시:\\n- 서울 안에서는 어디를 가볼까요? (관광·맛집 추천)\\n- 서울 안에서는 대중교통/택시 이용이 어떤가요?\\n- 서울 안에서는 배달/택배가 되나요?\\n- 서울 안에서는 코로나/방역 규칙은 어떤가요?\\n- 서울 안에서는 집값·월세는 어느 정도인가요?\\n- 서울 안에서는 주차 규정(혹은 자전거 관련) 어떻게 되나요?\\n\\n원하시는 항목이나 상세 조건(여행일정, 예산, 출발지 등)을 알려주시면 바로 도와드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ad719012c819eabfeea13ab32813c'}]\n",
      "\n",
      "03. [HUMAN] 안녕?\n",
      "\n",
      "04. [AI] [{'id': 'rs_0fc6438b81b8efa700690ad8f9809c819e8f43be7e22c372cd', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요? 이전에 쓰신 “서울 안에서는?” 관련해서\\n- 관광·맛집 추천\\n- 교통(지하철·버스·택시)\\n- 집값·월세 정보\\n- 배달·편의 서비스\\n- 방역·행사·날씨 등\\n\\n원하시는 항목과 날짜·예산·취향 같은 조건을 알려주시면 바로 도와드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ad8fce444819eb74f84e66cc7bd83'}]\n",
      "\n",
      "05. [HUMAN] 안녕?\n",
      "\n",
      "06. [AI] [{'id': 'rs_0fc6438b81b8efa700690ad97c341c819e8d0791ca949869f2', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요? 이전에 쓰신 “서울 안에서는?”과 관련해\\n- 관광·맛집 추천\\n- 교통(지하철·버스·택시)\\n- 숙박·집값·월세\\n- 배달·편의 서비스\\n- 행사·날씨·방역 등\\n\\n원하시는 항목이나 구체적인 질문을 알려주시면 바로 도와드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ad97e1f9c819eaf031e4dc4095fa7'}]\n",
      "\n",
      "07. [HUMAN] 안녕?\n",
      "\n",
      "08. [AI] [{'id': 'rs_0fc6438b81b8efa700690ae420d050819e96475bc32ea0fa6c', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요?\\n\\n원하시는 게 있으면 알려주세요. 예: 서울 관련 정보(관광·교통·맛집), 일정짜기, 번역, 글쓰기, 아니면 그냥 수다 등. 한국어/영어 중 어떤 언어로 대화할지도 알려주시면 맞춰드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ae423cb9c819e98c97e3e1e82c0e7'}]\n",
      "\n",
      "09. [HUMAN] 안녕?\n",
      "\n",
      "10. [AI] [{'id': 'rs_0fc6438b81b8efa700690ae4524f2c819ea62e337565bf7b78', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요?  \\n원하시는 게 있으면 말씀해 주세요. 예: 서울 정보(관광·맛집·교통), 일정짜기, 번역, 글쓰기, 아니면 그냥 수다도 좋아요. 어떤 언어로 대화할지도 알려주시면 맞춰드릴게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ae45534fc819eb9db061affa3fef1'}]\n",
      "\n",
      "11. [HUMAN] 안녕?\n",
      "\n",
      "12. [AI] [{'id': 'rs_0fc6438b81b8efa700690ae49f79a0819eb5ce7266a6a8d6cf', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 — 무엇을 도와드릴까요?  \\n원하시는 걸 짧게 알려주시면 바로 시작할게요. (예: 서울 정보, 여행 일정, 번역, 글쓰기, 잡담 등)', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ae4a19e80819e87f46091ff69bb90'}]\n",
      "\n",
      "13. [HUMAN] 안녕?\n",
      "\n",
      "14. [AI] [{'id': 'rs_0fc6438b81b8efa700690ae4a9efa0819ea374f5d0d79c7435', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 😊  \\n반가워요 — 어떻게 도와드릴까요?\\n\\n간단히 고르실래요?\\n- 수다/심심풀이\\n- 서울 추천(관광·맛집)\\n- 일정 짜기\\n- 번역·글쓰기 도움\\n- 퀴즈·간단한 게임\\n\\n원하시는 걸 한 단어만 써서 알려주시면 바로 시작할게요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690ae4aca550819e87dabe6eeaad537f'}]\n",
      "\n",
      "15. [HUMAN] 안녕?\n",
      "\n",
      "16. [AI] [{'id': 'rs_0fc6438b81b8efa700690aebf47b44819e80db589a90ffd458', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 😊  \\n무엇을 도와드릴까요? 아래에서 하나 골라 숫자만 보내주셔도 돼요.\\n\\n1) 수다/심심풀이  \\n2) 퀴즈·간단한 게임  \\n3) 서울 정보(관광·맛집·교통)  \\n4) 번역·글쓰기 도움  \\n5) 장난스러운 인사나 농담 듣기\\n\\n원하시는 게 있으면 숫자나 한 단어로 말씀해 주세요.', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690aebf71ea4819ebe61384728c135c8'}]\n",
      "\n",
      "17. [HUMAN] 안녕?\n",
      "\n",
      "18. [AI] [{'id': 'rs_0fc6438b81b8efa700690c333391fc819eb82632f5eaf7879d', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '안녕하세요! 반가워요 😊  \\n무엇을 도와드릴까요? 간단히 골라주세요—숫자나 한 단어로 알려주시면 바로 시작할게요.\\n\\n1) 수다  \\n2) 퀴즈/게임  \\n3) 서울 정보(관광·맛집·교통)  \\n4) 번역·글쓰기 도움  \\n5) 그냥 인사만', 'annotations': [], 'id': 'msg_0fc6438b81b8efa700690c3336e504819e959174f7d231071d'}]\n",
      "\n",
      "19. [HUMAN] langchain의 설계 철학에 대해 알려줘.\n",
      "\n",
      "20. [HUMAN] langchain의 설계 철학에 대해 알려줘.\n",
      "\n",
      "21. [HUMAN] langchain의 설계 철학에 대해 알려줘.\n",
      "\n",
      "22. [HUMAN] langchain의 설계 철학에 대해 알려줘.\n",
      "\n",
      "23. [AI] [{'id': 'rs_0fc6438b81b8efa700690c34e09e54819ea9050747c44c2c8c', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0fc6438b81b8efa700690c34e51e38819e9768279aa487b715', 'action': {'query': 'LangChain design philosophy', 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0fc6438b81b8efa700690c34e66ef8819e9639d181365d3a53', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0fc6438b81b8efa700690c34eb8e6c819e898bb555f3dd31ed', 'action': {'query': \"LangChain composability 'design' 'composable' LangChain docs\", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0fc6438b81b8efa700690c34edaaa8819ea7c67ef6f591cd76', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0fc6438b81b8efa700690c34f0c6e8819ea52fc1215d2d8590', 'action': {'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0fc6438b81b8efa700690c34f1f820819eb924af8b86c12f87', 'summary': [], 'type': 'reasoning'}, {'id': 'ws_0fc6438b81b8efa700690c34f46d5c819e8850a9b045dca855', 'action': {'query': \"LangChain retrieval augmented generation docs 'retriever' 'vector store' 'RAG' site:langchain.com\", 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'id': 'rs_0fc6438b81b8efa700690c34f5ff6c819eac80529e162f8a00', 'summary': [], 'type': 'reasoning'}, {'type': 'text', 'text': '짧히 요약하면, LangChain의 설계 철학은 “인터페이스 기반의 모듈성 + 조합성(컴포저블 파이프라인) + 제공자(모델/저장소) 불가지론 + 실전(프로덕션) 지원/관측성”에 있습니다. 아래에 핵심 아이디어와 그것이 코드/아키텍처에 어떻게 반영되는지 정리합니다.\\n\\n핵심 원칙\\n- 추상화(인터페이스) 중심: LLM, 임베딩, 벡터 스토어, 리트리버 등 핵심 컴포넌트는 공통 인터페이스로 정의되어 있어, 다른 구현(여러 모델·DB)을 쉽게 교체할 수 있습니다. 이로써 모델/서비스 교체에 따른 엔지니어링 비용을 줄입니다. ([python.langchain.com](https://python.langchain.com/v0.2/docs/concepts/?utm_source=openai))\\n\\n- 컴포지션(조합성): 작은 단위의 “Runnable/체인”을 파이프처럼 연결해 복잡한 워크플로를 구성하도록 설계했습니다(LCEL/ Runnable). 이 접근은 동기/비동기, 배치, 스트리밍 처리를 일관되게 지원하고 재사용성을 높입니다. ([python.langchain.com](https://python.langchain.com/docs/concepts/runnables/?utm_source=openai))\\n\\n- 명확한 역할 분리 — Chains vs Agents: 경로가 고정되어 있고 결정론적일 때는 Chain(하드코드된 순서)을 권장하고, 불확실하거나 도구(툴)를 동적으로 호출해야 할 때는 Agent(LLM이 다음 동작을 결정)를 사용하도록 구분되어 있습니다. 즉 “가능하면 deterministic chain, 필요시 agent”의 실용적 조언이 담겨 있습니다. ([python.langchain.com](https://python.langchain.com/v0.1/docs/modules/agents/concepts/?utm_source=openai))\\n\\n- 데이터 연동(특히 RAG)·상태: 문서 로더 → 텍스트 분할 → 임베딩 → 벡터 인덱스 → 리트리버 → LLM(생성)의 흐름을 표준화해 RAG(검색 보강 생성) 워크플로를 쉽게 만들 수 있게 했습니다. 또한 대화형 메모리(버퍼, 요약, 엔티티 등) 추상화를 제공해 상태 보존을 다룹니다. ([python.langchain.com](https://python.langchain.com/v0.2/docs/tutorials/rag/?utm_source=openai))\\n\\n- 관측성·운영성: 실행(trace), 콜백, 토큰·시간 측정 등 관측(디버깅·평가)을 염두에 둔 API와 LangSmith 같은 도구(트레이싱/평가/배포)와의 연계를 강조합니다. 제품화(배포·디버깅) 관점이 설계에 포함되어 있습니다. ([python.langchain.com](https://python.langchain.com/docs/concepts/lcel/?utm_source=openai))\\n\\n설계적 결과(개발자 경험 측면)\\n- 경량 코어 + 통합 패키지 구조: 핵심 추상만을 담은 경량 패키지와(예: core) 다양한 외부 통합을 별도 패키지로 분리해 의존성을 관리합니다. 이는 테스트·유지보수를 쉽게 합니다. ([python.langchain.com](https://python.langchain.com/v0.2/docs/concepts/?utm_source=openai))\\n- 선언적·재사용 가능한 구성: LCEL/Runnable 같은 선언적 구성으로 파이프라인을 정의하면 런타임 최적화(병렬화, 스트리밍 등)와 일관된 동작을 얻을 수 있습니다. ([python.langchain.com](https://python.langchain.com/docs/concepts/lcel/?utm_source=openai))\\n- 실무 권장(안내): 불필요한 에이전트 사용 지양(툴이 너무 많으면 잘못된 선택을 할 수 있음), 메모리·컨텍스트는 비용·위험(드리프트)을 고려해 신중히 사용하라는 실용적 가이드가 문서 전반에 걸쳐 제시됩니다. ([python.langchain.com](https://python.langchain.com/v0.1/docs/modules/agents/concepts/?utm_source=openai))\\n\\n짧은 결론\\n- LangChain은 LLM 애플리케이션을 “미리 설계된 블록(인터페이스)들을 조합”해 빠르게 구축·운영하도록 만드는 데 초점을 둔 프레임워크입니다. 개발 편의성(교체성·조합성)과 운영 편의성(관측성·배포)을 모두 고려한 실용적 설계 철학을 가지고 있습니다. ([github.com](https://github.com/langchain-ai/langchain))\\n\\n원하시면:\\n- 예시 코드(간단한 RAG 체인 또는 LCEL 기반 파이프라인)를 보여드릴게요.\\n- 또는 “Agent vs Chain” 을 실제 코드로 비교해 드릴까요?', 'annotations': [{'end_index': 383, 'start_index': 291, 'title': 'Conceptual guide | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.2/docs/concepts/?utm_source=openai'}, {'end_index': 616, 'start_index': 519, 'title': 'Runnable interface | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/docs/concepts/runnables/?utm_source=openai'}, {'end_index': 928, 'start_index': 821, 'title': 'Concepts | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.1/docs/modules/agents/concepts/?utm_source=openai'}, {'end_index': 1190, 'start_index': 1093, 'title': 'Build a Retrieval Augmented Generation (RAG) App | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.2/docs/tutorials/rag/?utm_source=openai'}, {'end_index': 1416, 'start_index': 1324, 'title': 'LangChain Expression Language (LCEL) | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/docs/concepts/lcel/?utm_source=openai'}, {'end_index': 1633, 'start_index': 1541, 'title': 'Conceptual guide | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.2/docs/concepts/?utm_source=openai'}, {'end_index': 1823, 'start_index': 1731, 'title': 'LangChain Expression Language (LCEL) | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/docs/concepts/lcel/?utm_source=openai'}, {'end_index': 2050, 'start_index': 1943, 'title': 'Concepts | 🦜️🔗 LangChain', 'type': 'url_citation', 'url': 'https://python.langchain.com/v0.1/docs/modules/agents/concepts/?utm_source=openai'}, {'end_index': 2261, 'start_index': 2204, 'title': 'GitHub - langchain-ai/langchain:  The platform for reliable agents.', 'type': 'url_citation', 'url': 'https://github.com/langchain-ai/langchain'}], 'id': 'msg_0fc6438b81b8efa700690c34ff57c0819e80adb2ca0089bf26'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 저장된 데이터를 조회해보겠습니다.\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# DB를 조회할 때도, with문 아래에서 checkpointer를 호출해야 합니다.\n",
    "with SqliteSaver.from_conn_string(\"checkpoints.db\") as saver:\n",
    "    checkpoint_tuple = saver.get_tuple({\"configurable\": {\"thread_id\": \"1\"}})\n",
    "\n",
    "    # 이하는 db에 저장된 객체에서 사용자와 AI의 대화 부분만 파싱하여 출력하기 위한 코드입니다.\n",
    "    # 불필요하게 복잡하고 보기에도 불편하므로, langsmith key를 연결해놓고 거기서 확인하는게 좋습니다.\n",
    "    checkpoint_data = checkpoint_tuple.checkpoint\n",
    "    messages = checkpoint_data[\"channel_values\"][\"messages\"]\n",
    "\n",
    "    for i, msg in enumerate(messages, 1):\n",
    "        msg_type = getattr(msg, \"type\", msg.__class__.__name__)\n",
    "        print(f\"{i:02d}. [{msg_type.upper()}] {msg.content}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c40c0",
   "metadata": {},
   "source": [
    "### ※ 참고\n",
    "- 단기 메모리든 장기 메모리든, 모델은 쌓여 있는 모든 대화기록을 input받아 대답합니다.\n",
    "- 따라서 세션 내 대화가 길어질수록 token 사용량이 급격히 늘어나고, 모델이 한 번에 처리할 수 없는 양이 되면 오류를 발생시킵니다.\n",
    "- 오래된 메시지를 제거하거나 요약하는 등의 방법으로 제어해야 하는데, 마지막 챕터인 미들웨어에서 간단하게 다뤄보겠습니다.\n",
    "- 서비스 개발시 반드시 공식문서를 참조하여 구현해보시기 바랍니다.\n",
    "  - https://docs.langchain.com/oss/python/langchain/short-term-memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df97746",
   "metadata": {},
   "source": [
    "## 6. 스트리밍\n",
    "\n",
    "- Agent의 반복적인 추론으로 인한 지연 시간은 UX를 크게 저하시킵니다.\n",
    "- 출력을 점진적으로 표시하는 스트리밍 기능을 통해 보완해봅시다.\n",
    "- OpenAI API는 스트리밍 기능 사용을 위해 기관 인증을 요구하므로 지금은 사용할 수 없습니다.\n",
    "- Ollama 로컬 LLM을 활용하여 맛만 봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "47ea020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Ollama 데스크탑 앱을 설치하고, 터미널에서 사용할 모델(gemma3)를 미리 다운받아야 합니다.\n",
    "# ollama pull gemma3\n",
    "\n",
    "# 모델 지정\n",
    "model = ChatOllama(\n",
    "    model=\"gemma3\",\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "# Agent 생성 및 tool 전달\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "# Agent에 전달할 메시지 객체를 생성합니다.\n",
    "messages = [\n",
    "    HumanMessage(content=\"Who is the best football player in history?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d65338bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Okay'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' this'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' is'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' *'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' question'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' that'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' sparks'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' endless'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' debate'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' in'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' football'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'soccer'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ')'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' fandom'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '!'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' There'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': \"'\"}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' no'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' single'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' definitive'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' answer'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' to'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' \"'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'who'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' is'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' best'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' football'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' player'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' in'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' history'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ',\"'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' but'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Lionel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Messi'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' is'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' overwhelmingly'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' most'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' popular'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' frequently'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' cited'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' answer'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' *'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'today'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' However'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Pel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'é'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' still'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' has'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' a'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' very'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' strong'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' claim'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Let'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': \"'\"}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' break'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' down'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' arguments'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' each'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Lionel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Messi'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Arguments'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Record'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '-'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Breaking'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Goal'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'scoring'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Messi'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' holds'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' numerous'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' goal'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'scoring'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' records'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Barcelona'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Argentina'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' La'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Liga'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' He'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '’'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' consistently'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' scored'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' at'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' an'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' incredible'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' rate'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' throughout'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' his'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' career'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'D'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'rib'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'bling'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' &'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Play'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'making'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' His'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' drib'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'bling'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ability'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' is'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' considered'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' unparalleled'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' –'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' he'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' can'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' seemingly'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' weave'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' through'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' defenders'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' with'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ease'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' He'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '’'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' also'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' a'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' brilliant'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' playmaker'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' creating'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' chances'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' teammates'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Ball'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'on'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' d'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': \"'\"}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Or'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Awards'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' He'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' has'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' a'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' record'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' eight'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Ballon'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' d'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': \"'\"}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Or'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' awards'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' recognizing'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' him'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' as'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' world'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '’'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' best'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' player'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Recent'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Achievements'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '):'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Winning'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' FIFA'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' World'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Cup'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' with'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Argentina'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' cemented'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' his'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' legacy'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' silenced'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' many'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' of'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' his'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' remaining'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' critics'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Lon'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'gevity'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' &'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Consistency'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '  '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'He'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': \"'\"}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' been'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' performing'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' at'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' an'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' elite'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' level'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' over'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '5'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' years'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Pel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'é'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Arguments'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Three'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' World'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Cup'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Wins'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Pel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'é'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' is'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' only'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' player'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' to'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' have'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' won'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' three'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' FIFA'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' World'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Cups'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '9'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '5'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '8'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '9'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '6'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '9'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '7'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ').'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' This'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' is'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' a'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' hugely'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' significant'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' factor'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' in'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' debate'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Revolution'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'ized'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Game'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' He'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' brought'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' a'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' new'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' level'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' of'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' athleticism'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' flair'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' to'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' football'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' in'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' early'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' days'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' of'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' sport'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Amazing'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Goal'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'scoring'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Record'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '  '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'He'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' scored'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' over'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' career'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' goals'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'though'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' exact'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' number'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' is'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' debated'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ').'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Global'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Icon'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' He'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' was'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' a'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' global'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' superstar'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' before'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' anyone'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' else'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' helping'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' to'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' popular'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'ize'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' sport'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' worldwide'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Here'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': \"'\"}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' a'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' quick'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' comparison'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' table'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Feature'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '          '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Lionel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Messi'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '        '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Pel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'é'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '                 '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '----------------'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '--'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '----------------'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '-----'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '----------------'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '------'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'World'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Cups'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '     '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'though'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' he'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' was'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' part'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' of'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' winning'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' squad'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ')'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' |'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '3'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '                    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Goal'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'scoring'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '     '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ~'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '7'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '+'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'offic'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'ially'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ')'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '    '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ~'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '+'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'estimated'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ')'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '  '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'D'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'rib'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'bling'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '       '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Argu'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'ably'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' best'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ever'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' |'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Exceptional'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' his'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' time'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' |'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Impact'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' on'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Game'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' |'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Revolution'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'ized'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' modern'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' play'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' |'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Popular'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'ized'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' football'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' globally'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' |'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Era'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '           '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '2'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'st'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Century'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '        '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '9'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '5'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '-'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '9'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '7'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '0'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '          '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '|'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Other'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Players'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Often'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Mention'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'ed'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ('}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'but'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' generally'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' considered'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' slightly'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' behind'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Messi'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Pel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'é'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '):'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Diego'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Maradona'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '  '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'A'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' legendary'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' figure'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' particularly'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' his'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' performance'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' in'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '1'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '9'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '8'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '6'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' World'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Cup'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' **'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Cristiano'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Ronaldo'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '  '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'A'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' phenomenal'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' goal'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'scorer'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' athlete'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' who'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' has'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' consistently'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' performed'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' at'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' highest'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' level'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Conclusion'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Currently'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' most'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' experts'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' fans'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' consider'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Lionel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Messi'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' to'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' be'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' greatest'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' football'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' player'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' of'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' all'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' time'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' His'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' goal'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'scoring'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' record'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' drib'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'bling'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' ability'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' recent'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' World'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Cup'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' victory'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' have'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' solidified'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' his'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' position'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '  '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'However'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Pel'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'é'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': \"'\"}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' historical'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' significance'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' –'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' particularly'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' his'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' three'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' World'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' Cup'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' triumphs'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' –'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' keeps'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' him'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' in'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' the'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' conversation'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' his'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' legacy'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' is'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' undeniable'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Ultimately'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' it'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '’'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 's'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' a'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' matter'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' of'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' personal'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' preference'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' and'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' what'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' criteria'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' you'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' value'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' most'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '.**'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Do'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' you'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' want'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' me'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' to'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' delve'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' deeper'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' into'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' any'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' specific'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' aspect'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' of'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' this'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' debate'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ','}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' such'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' as'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ':'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '   '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'Specific'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' statistics'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '?'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '   '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'The'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' different'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' eras'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' of'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' football'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '?'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '\\n'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '*'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '   '}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': 'The'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' arguments'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' for'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' other'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': ' players'}]\n",
      "node: model\n",
      "content: [{'type': 'text', 'text': '?'}]\n",
      "node: model\n",
      "content: []\n",
      "node: model\n",
      "content: []\n"
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 확인하기 위해 내용을 파일에 저장하겠습니다.\n",
    "# ollama 실행 및 gemma3 모델 pull이 되어있지 않으면 여기서 오류가 발생합니다.\n",
    "with open(\"stream_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    # agent.stream()으로 호출\n",
    "    for token, metadata in agent.stream(\n",
    "        {\"messages\": messages}, # HumanMessage 객체 전달\n",
    "        stream_mode=\"messages\", # 스트림으로 받을 단위 설정\n",
    "    ):\n",
    "        # 노트북 셀 출력\n",
    "        print(f\"node: {metadata['langgraph_node']}\")\n",
    "        print(f\"content: {token.content_blocks}\")\n",
    "        \n",
    "        # 파일에 저장\n",
    "        f.write(f\"node: {metadata['langgraph_node']}, \")\n",
    "        f.write(f\"content: {token.content_blocks}\")\n",
    "        f.write('\\n')\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14389b9b",
   "metadata": {},
   "source": [
    "## 7. 미들웨어\n",
    "\n",
    "- 미들웨어를 통해 에이전트의 추론 과정 중간에 개입하여 내부 동작을 커스터마이징할 수 있습니다.\n",
    "- Agent를 세부적으로 커스터마이징하기 위한 대부분의 작업이 미들웨어를 통합니다.\n",
    "  - 대화 기록 요약\n",
    "  - 동작 중 사용자 입력 대기\n",
    "  - 특정 모델 또는 tool에 대한 호출 제약\n",
    "  - fallback\n",
    "  - PII(개인식별정보) 처리 등\n",
    "- 몇 가지만 간단하게 구현해보겠습니다. 서비스 개발시 공식 문서를 참조하여 다른 기능들도 적용해보세요!\n",
    "  - https://docs.langchain.com/oss/python/langchain/middleware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb40759",
   "metadata": {},
   "source": [
    "### 7-1. 대화 기록 요약\n",
    "- 대화가 지속될 때 context가 무한히 늘어나지 않도록 이전 대화 기록을 요약해서 전달해봅시다.\n",
    "- 작업의 특성에 따라 성능을 크게 하락시킬 수 있으니 적용 시 충분한 테스트가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4a3a39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미들웨어에서 대화 기록을 요약하기 위해 사용되는 모듈입니다.\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "# 요약하려면 기록이 있어야 하니까, 단기 메모리를 만들어 줍니다.\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# model 정의\n",
    "model = init_chat_model(\n",
    "    model=\"openai:gpt-5-mini\",\n",
    "    max_tokens=8000,\n",
    "    )\n",
    "\n",
    "# 사용할 middleware 객체를 미리 정의합니다.\n",
    "middleware_summarize = SummarizationMiddleware(\n",
    "            model=model, # 요약하는 데에 쓸 모델. 물론 Agent 모델과 다른 걸 써도 됨\n",
    "            max_tokens_before_summary=1000, # 모델이 처리해야 할 토큰 수가 임계치를 넘으면, 요약을 먼저 수행합니다. 추론이 동작하는지 확인하기 위해 매우 작은 값으로 설정했습니다.\n",
    "            messages_to_keep=1, # 요약에 포함시키지 않을 최근 메시지의 수를 결정합니다. 너무 낮게 설정하면 최근 대화에 대한 맥락이 소실되니 주의하세요.\n",
    "            # summary_prompt=\"요약할 때 이렇게 저렇게 해줘.. 커스터마이징 프롬프트 사용 가능\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Agent 생성\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    checkpointer=InMemorySaver(), # 단기 메모리를 저장할 checkpointer 객체 지정\n",
    "    middleware=[middleware_summarize, ], # 위에서 정의한 middleware를 Agent에게 전달합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f14019a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Here is a summary of the conversation to date:\\n\\n(Elphaba 1인칭 요약)\\n- 초록 피부로 태어나 ‘다르다’고 낙인찍힌 이상주의자. 아버지 부재·가정 갈등·언니와의 대비로 외로움과 정의감 형성.\\n- 아카데미에서 글린다를 만나 우정이 생기지만 오해와 충돌을 겪음. 마법사와 체제의 위선을 발견하고 진실을 말하려다 추격당함.\\n- 피에로와의 로맨스에서 위로와 혼란을 경험. 결국 공개적으로 체제에 맞서며 사람들에게 ‘위키드’로 낙인찍힘.\\n- 핵심 주제: ‘다름’으로 인한 고통, 타인을 구하려는 희생, 글린다와의 복합적 연결이 만드는 변화.\\n\\n연기 포인트(핵심)\\n1) 내적 동기와 목표\\n- 중심 목표: 인정받고 세상을 바꾸고자 하는 열망을 모든 장면에서 보이게.\\n- 장면별 작은 목표(이해받기, 화해, 보호, 폭로 등)를 분명히 설정.\\n- 에너지 흐름: 이상→희망→좌절·분노→결의·희생.\\n\\n2) 감정의 아크\\n- 초반: 소외·신중하지만 눈빛엔 불꽃.\\n- 중반: 희망과 좌절 교차, 분노·씁쓸함 상승.\\n- 후반: 확고한 결의와 외로움, 강하고 넓은 표현 필요.\\n\\n3) 신체성\\n- 초반: 어깨 닫힘, 서투른 걸음, 긴장된 손동작.\\n- 친밀해질수록 몸이 풀림(어색한 미소 포함).\\n- 정체성 확립 시: 가슴을 열고 시선·자세 상승.\\n- ‘다름’ 표시에 작은 신체 반응(눈썹·한숨·피부 만짐) 활용.\\n\\n4) 표정·눈빛\\n- 초록 메이크업으로 세부 표정 묻힘 → 눈과 입 표현을 더 크고 명확하게.\\n- 분노: 좁고 강한 눈빛. 상처: 크게 뜬 눈과 물기. 결의: 고정된 시선.\\n- 진심의 웃음은 눈부터, 위선은 입부터.\\n\\n5) 보컬(노래별)\\n- 전반: 안정된 브레스, 체스트↔믹스 전환 자연스럽게.\\n- The Wizard and I: 맑고 희망적 톤, 또렷한 발음.\\n- I’m Not That Girl / As Long as You’re Mine: 취약성, breathy·떨림 사용 가능.\\n- Defying Gravity: 클라이맥스. 지르지 않고 지구력 유지. 에너지 절약과 어택 컨트롤 중요.\\n- 체력 관리: 워밍업/쿨다운 필수.\\n\\n6) 관계 연기\\n- Glinda: 경쟁·거울·위안·상처가 혼재. 장면마다 감정 비중 조절.\\n- Fiyero: 보호받고 싶은 감정과 혼란의 진폭 표현.\\n- Wizard/Madame Morrible: 정치적 환멸과 냉소.\\n- 군중: 외면·적대 반응에 즉각 리액션.\\n\\n7) 무대·기술·분장 실무\\n- 특수효과(부상/levitation 등): 안전 점검·타이밍 훈련 필수.\\n- 스팟·조명 대비 시선 처리, 마이크 체크 중요.\\n- 소품(빗자루·모자) 사용법 숙지.\\n- 초록 메이크업: 프라이머·철저한 클렌징·보습. 콘택트 안전검사.\\n\\n8) 연습 팁\\n- 장면 전후의 ‘비하인드’ (무대 뒤 독백) 작성해 리얼리티 강화.\\n- 핵심 단어별 의도 설정(어떤 단어에 힘을 줄지).\\n- 중요한 라인의 리듬/타이밍을 여러 방식으로 실험.\\n- 배우와 물리적 거리·손 위치·눈맞춤 타이밍을 반복적으로 맞춤.\\n\\nGlinda를 바라보는 감정 요약 및 장면별 지침\\n- 전체 원칙: 단일 감정 불충분 — 경쟁자이자 거울, 위안이자 상처. ‘복합적 애정과 상처’ 표현.\\n- 만남 초반: 호기심 + 경계 — 눈 크게, 어색한 미소, 신중한 톤.\\n- 우정 성장기: 희망·안도 — 어깨 풀림, 눈맞춤 길게, 부드러운 톤.\\n- 충돌/실망 시기: 배신감·분노·쓸쓸함 — 차가운 눈빛, 단호한 짧은 말투, 억압된 분노 표현.\\n- Fiyero 관련 갈등: 질투·혼란·연민이 혼재 — 미세한 표정 변화(눈썹·입꼬리), 때로 부드러워짐.\\n- 용서·작별(For Good): 진정한 애정·감사·슬픔 — 오래 지속되는 눈맞춤, 작은 미소·눈물, 안정된 낮은 톤.\\n\\n구체적 테크닉 팁(Glinda 관련)\\n- 눈맞춤의 질로 감정 조절(정면=친밀, 슬쩍보기=경계/질투).\\n- 물리적 거리 변화로 관계 변화 시각화.\\n- 터치 의미 부여(잡음=신뢰, 회피=배신).\\n- 목소리 색깔: 친밀 시 부드럽게, 충돌 시 딱 끊는 발음.\\n- 내부 독백: 각 장면 전에 “지금 Glinda에게 무엇을 바라는가?” 1문장으로 정함.\\n\\n주의사항(Do/Don’t)\\n- Do: 단순 적대감으로 치우치지 말고 사랑과 상처의 복합성 유지.\\n- Don’t: Glinda를 완전한 악역으로만 묘사하지 말 것.\\n- Do: 미세한 리액션 연습으로 자연스러운 감정 드러냄.\\n- Don’t: 감정 전환을 동기 없이 급격하게 극단화하지 말 것.', additional_kwargs={}, response_metadata={}, id='9fc693d5-4c61-4b3e-ab66-c6e904457180'),\n",
      "              HumanMessage(content='도와줘서 고마워. 연기 잘 해볼게.', additional_kwargs={}, response_metadata={}, id='da5c40a7-d2e9-475c-9415-6ef125c2cc30'),\n",
      "              AIMessage(content='정말 잘하실 거예요 — 준비하신 게 탄탄해서 연기만 하시면 됩니다. 마지막으로 무대에 오르기 전 유용한 짧은 체크리스트와 루틴 드릴게요.\\n\\n간단 체크리스트\\n- 중심 목표 한 문장으로 정리: 지금 이 장면에서 내가 원하는 것(예: “그녀에게 내 진심을 이해받고 싶다”).\\n- 호흡·발성: 짧고 얕은 호흡 말고 깊은 복식 3회, 발성 가볍게 풀기.\\n- 눈맞춤 의도: Glinda에게 무엇을 요구하는지에 따라 시선의 길이와 강도 결정.\\n- 신체 포인트 하나(어깨, 손, 몸무게 중심) 고정: 작은 변화로 감정 아크 표현.\\n- 기술·분장 확인: 마이크·콘택트·소품(빗자루 등) 최소 1회 리허설.\\n\\n무대 직전 90초 루틴\\n1) 몸 풀기: 목·어깨·팔 빠르게 흔들기(20초).  \\n2) 발성·호흡: 복식호흡 3회 → 한 문장 크게 말해보기(대사 중 핵심 문장).  \\n3) 내부 문장: “지금 나는 ○○을 바란다” 한 문장 마음속으로 반복.  \\n4) 파워포즈 10초(가슴 열고 고개 약간 듦) → 집중해서 무대로.\\n\\n마지막 팁\\n- 감정은 ‘지금’에 머물게: 과거 설명이 아닌 현재의 행동으로 표현하세요.  \\n- 에너지 분배: 초반에 아껴서 클라이맥스에서 품질 유지.  \\n- 리액션 잊지 말기: 군중·Glinda의 한마디에 즉각 반응하면 진짜감이 살아납니다.\\n\\n필요하면 특정 씬(예: Defying Gravity 마지막 2절, Glinda와의 For Good) 리허설용 대사·내적 독백 도와드릴게요. 화이팅—무대에서 빛나세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 607, 'prompt_tokens': 1443, 'total_tokens': 2050, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYn7F7l7nHQTWu9EIOoaB5vEmUbuR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--9791986c-1064-4f3e-be16-0b75939e55f4-0', usage_metadata={'input_tokens': 1443, 'output_tokens': 607, 'total_tokens': 2050, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}})]}\n"
     ]
    }
   ],
   "source": [
    "# Agent가 요약을 실행하고 있는지 응답을 확인해봅시다.\n",
    "\n",
    "# Agent에 전달할 메시지 객체를 생성합니다.\n",
    "messages = [\n",
    "    HumanMessage(content=\"뮤지컬 Wicked의 내용을 Elphaba 입장에서 서술해줘. 그리고 그 내용을 기반으로 Elphaba를 연기할 때 신경써야 할 포인트들을 짚어줘.\"),\n",
    "]\n",
    "\n",
    "# Agent 호출\n",
    "response = agent.invoke(\n",
    "    {\"messages\":messages},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}, # 단기 메모리를 저장할 쓰레드 번호를 전달합니다.\n",
    "    )\n",
    "\n",
    "# Agent 호출을 반복하여 대화 기록을 쌓아 봅시다.\n",
    "messages = [\n",
    "    HumanMessage(content=\"Glinda를 어떤 감정으로 바라보는게 좋을까?\"),\n",
    "]\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\":messages},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}, \n",
    "    )\n",
    "\n",
    "# 세 번째 호출!\n",
    "messages = [\n",
    "    HumanMessage(content=\"도와줘서 고마워. 연기 잘 해볼게.\"),\n",
    "]\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\":messages},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}, \n",
    "    )\n",
    "\n",
    "# 마지막 호출에 대한 응답만 확인해보겠습니다.\n",
    "# langsmith로 가서, middleware가 어떻게 호출되었는지 꼭 확인해보세요!\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2e7a9",
   "metadata": {},
   "source": [
    "### 7-2. PII(개인식별정보) 처리\n",
    "- 사용자가 잘못해서 자신의 개인정보를 입력하더라도, 그 내용이 사용자 동의 없이 그대로 우리 DB에 저장되어서는 안 되겠죠.\n",
    "- PII를 자동으로 감지하고 정보의 특성에 맞게 처리해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미들웨어에서 PII를 처리하기 위한 모듈입니다.\n",
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "# 사용할 middleware 객체를 미리 정의합니다. 세 개의 PII를 각각 처리해봅시다.\n",
    "middleware_email = PIIMiddleware(\n",
    "    pii_type='email', # 이메일\n",
    "    detector=r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", # 정규표현식으로 이메일 패턴을 정의합니다.\n",
    "    strategy='redact', # PII 삭제\n",
    "    apply_to_input=True, # 입력값에 대해 PII 처리 로직 발동\n",
    ")\n",
    "\n",
    "middleware_credit_card = PIIMiddleware(\n",
    "    pii_type='credit_card', # 신용카드 번호\n",
    "    strategy='mask', # 마스킹 처리\n",
    "    apply_to_input=True,\n",
    ")\n",
    "\n",
    "middleware_api_key = PIIMiddleware(\n",
    "    pii_type='api_key', # API 키\n",
    "    detector=r\"sk-[a-zA-Z0-9]{32}\", # OpenAI API key의 패턴입니다.\n",
    "    strategy='block', # 오류 발생\n",
    ")\n",
    "\n",
    "# agent 생성\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    middleware=[middleware_email, middleware_credit_card, middleware_api_key], # 위에서 정의한 세 개의 PII 처리 middleware를 전달합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aee902e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='AWS 요금이 4백만 원 청구됐어. 깎아달라고 불쌍하게 비는 메일좀 써줘. 내 AWS 계정은 [REDACTED_EMAIL]이야.', additional_kwargs={}, response_metadata={}, id='39b803b6-2ab0-4132-9199-7c6659984388'),\n",
      "              AIMessage(content='아래는 AWS에 청구 감면(또는 크레딧 요청)을 정중하고 간절하게 요청하는 메일 템플릿입니다. 계정 정보, 청구서 번호, 사용내역 등 실제 정보를 괄호 안에 채워서 보내세요.\\n\\n제목:\\n긴급 도움 요청 — 예상치 못한 AWS 요금 4,000,000원 청구 관련 감면/크레딧 요청 (계정: [REDACTED_EMAIL])\\n\\n본문:\\n안녕하세요, AWS 고객지원팀 귀하\\n\\n저는 [이름/회사명]이며, AWS 계정([REDACTED_EMAIL])으로 서비스를 이용 중입니다. 이번 달 청구서에서 예상치 못하게 4,000,000원이 청구되어 매우 당황하고 있습니다. 저는 현재 개인(또는 소규모 사업자/학생 등)으로서 이 비용을 감당하기 어려운 상황입니다.\\n\\n상세 내용:\\n- 청구 금액: 약 4,000,000원\\n- 청구서/인보이스 번호: [인보이스 번호 또는 결제 내역 ID]\\n- 청구일/기간: [청구 기간]\\n- 의심되는 서비스/리전: [예: EC2 서울 리전, S3 등 — 가능하면 구체적으로 기재]\\n- 특이사항: (예: 사용량 급증을 미처 인지하지 못했음 / 계정 일부가 악용된 의심 / 무료 체험 종료 후 자동 과금 등)\\n\\n저는 이번 청구가 저의 경제적 상황에 큰 부담이 되어 감면이나 크레딧을 간곡히 요청드립니다. 만약 부당한 사용(계정 탈취 등)으로 인한 것이라면 조사에 적극 협조하겠습니다. 먼저 다음 조치를 취해 두었습니다.\\n- 현재 사용 중인 리소스(인스턴스/서비스)를 중지/종료함\\n- 루트 계정 및 IAM 비밀번호 변경, 액세스 키 비활성화(또는 회수)\\n- 결제 수단 잠정 중지(가능한 경우)\\n\\n정말 간절한 마음으로 도와주시길 부탁드립니다. 가능하시다면 일부 혹은 전액 감면, 또는 향후 사용을 위한 크레딧 부여 등을 검토해 주시면 감사하겠습니다. 추가로 필요한 정보가 있으면 바로 제공하겠습니다.\\n\\n부디 긍정적인 답변 부탁드립니다.\\n감사합니다.\\n\\n이름: [실명]\\n연락처: [전화번호]\\n계정 이메일: [REDACTED_EMAIL]\\n계정 ID (가능하면): [AWS 계정 ID]\\n\\n추가 안내(권장 행동)\\n- AWS Support 콘솔에서 Billing 지원 케이스 생성: https://console.aws.amazon.com/support/home#/case/create?issueType=billing\\n- 지원 케이스에 위 템플릿을 붙여넣고 인보이스 스크린샷, 최근 결제 내역, 의심 활동 스크린샷 등 증빙 첨부\\n- 계정이 탈취된 의심이 들면 바로 액세스 키 비활성화, 루트 계정 다중인증(MFA) 설정, CloudTrail/CloudWatch 로그 확인\\n- 앞으로 유사 상황 방지를 위해 예산(Budgets)과 알람 설정, 비용 탐지(Reserved Instance, Savings Plans 등) 활성화\\n\\n필요하시면 위 메일을 영어 버전으로 바꿔드리거나, 첨부할 증빙 문구를 함께 만들어 드릴게요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1473, 'prompt_tokens': 54, 'total_tokens': 1527, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 704, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYn7QiBa1UWbCriVMSOsSEr5tebFW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8a22bde6-aabb-4647-9227-0d91ae5ab1a4-0', usage_metadata={'input_tokens': 54, 'output_tokens': 1473, 'total_tokens': 1527, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 704}})]}\n"
     ]
    }
   ],
   "source": [
    "# email 정보를 포함하여 agent를 호출해봅시다.\n",
    "messages = [\n",
    "    HumanMessage(content=\"AWS 요금이 4백만 원 청구됐어. 깎아달라고 불쌍하게 비는 메일좀 써줘. 내 AWS 계정은 sapy123@gmail.com이야.\"),\n",
    "]\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\":messages},\n",
    "    )\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "49df576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='환불 요청 메일좀 써줘. 내 결제 정보야.\\nname: Jerry\\nproduct: youtube premium\\nprice: $8.80\\ncredit card: 4239-1282-8367-7743', additional_kwargs={}, response_metadata={}, id='f8526f13-36be-4411-b31f-0706b81a34ca'),\n",
      "              AIMessage(content='죄송하지만 보안상 전체 신용카드 번호(예: 4239-1282-8367-7743)는 이메일 내용에 포함해 드릴 수 없습니다. 대신 카드 번호를 제외한 형태로 환불 요청 메일 예시를 아래에 준비했습니다. 원하시면 카드 끝 4자리(7743), 거래일자, 거래ID(영수증 번호) 등 민감도가 낮은 정보만 추가해 드리겠습니다.\\n\\n제목: YouTube Premium 환불 요청 (결제 금액 $8.80)\\n\\n본문:\\n안녕하세요, YouTube 고객지원팀 담당자님께\\n\\n제 이름은 Jerry입니다. 아래 결제 건에 대해 환불을 요청드립니다.\\n\\n- 상품: YouTube Premium\\n- 결제 금액: $8.80\\n- 결제일자: [결제일자 입력]\\n- 결제 계정(이메일): [구독에 사용한 이메일 주소 입력]\\n- 결제수단: 신용카드(끝 4자리: 7743) 또는 [결제수단 정보 입력]\\n- 거래ID/영수증 번호: [있다면 입력]\\n\\n환불 사유: [예: 실수로 중복 결제됨 / 원치 않는 결제 발생 / 기타 사유 간단히 기재]\\n\\n환불은 원래 결제에 사용된 수단으로 처리해 주시길 요청드립니다. 환불 처리 가능 여부 및 필요하신 추가 정보(영수증 사본, 거래ID 등)를 안내해 주시면 감사하겠습니다.\\n\\n연락처: [전화번호 또는 대체 이메일 입력]\\n\\n감사합니다.\\nJerry 드림\\n\\n참고: 이메일로 전체 카드번호를 보내지 마시고, 필요 시 고객지원 포털의 안전한 입력란이나 고객센터 전화로 제공하시길 권장드립니다. 추가 정보 넣어 드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1298, 'prompt_tokens': 53, 'total_tokens': 1351, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYn7jXOpeCVR3um395IoVrfNKZ92l', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--de8e6b62-942f-4cec-ba78-9b0b6e365640-0', usage_metadata={'input_tokens': 53, 'output_tokens': 1298, 'total_tokens': 1351, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})]}\n"
     ]
    }
   ],
   "source": [
    "#  신용카드 번호를 포함하여 agent를 호출해봅시다.\n",
    "messages = [\n",
    "    HumanMessage(content=\"환불 요청 메일좀 써줘. 내 결제 정보야.\\nname: Jerry\\nproduct: youtube premium\\nprice: $8.80\\ncredit card: 4239-1282-8367-7743\"),\n",
    "]\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\":messages},\n",
    "    )\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8df7ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "PIIDetectionError",
     "evalue": "Detected 1 instance(s) of api_key in text content",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPIIDetectionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[129]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m messages = [\n\u001b[32m      3\u001b[39m     HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33m내가 env 변수명 잘못 설정했나??\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m OPENAPI_API_KEY=sk-proj4a2fcd5a1bdbd09e4fdd020d07b6a4380c84fdb07be5f674c5fa8e39b35e\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      4\u001b[39m ]\n\u001b[32m      6\u001b[39m \u001b[33;03m''' 아래 코드는 실행시 PIIDetectionError가 발생합니다!\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03mPIIDetectionError: Detected 1 instance(s) of api_key in text content\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03mDuring task with name 'PIIMiddleware[api_key].before_model' and id '95c50dad-870c-5ce6-6178-0d9b216c4341'\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m pprint(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\miniconda3\\envs\\langchain_1.0_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\miniconda3\\envs\\langchain_1.0_env\\Lib\\site-packages\\langgraph\\pregel\\main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\miniconda3\\envs\\langchain_1.0_env\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\miniconda3\\envs\\langchain_1.0_env\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\miniconda3\\envs\\langchain_1.0_env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\miniconda3\\envs\\langchain_1.0_env\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\miniconda3\\envs\\langchain_1.0_env\\Lib\\site-packages\\langchain\\agents\\middleware\\pii.py:198\u001b[39m, in \u001b[36mPIIMiddleware.before_model\u001b[39m\u001b[34m(self, state, runtime)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m last_user_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_user_msg \u001b[38;5;129;01mand\u001b[39;00m last_user_msg.content:\n\u001b[32m    196\u001b[39m     \u001b[38;5;66;03m# Detect PII in message content\u001b[39;00m\n\u001b[32m    197\u001b[39m     content = \u001b[38;5;28mstr\u001b[39m(last_user_msg.content)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     new_content, matches = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m matches:\n\u001b[32m    201\u001b[39m         updated_message: AnyMessage = HumanMessage(\n\u001b[32m    202\u001b[39m             content=new_content,\n\u001b[32m    203\u001b[39m             \u001b[38;5;28mid\u001b[39m=last_user_msg.id,\n\u001b[32m    204\u001b[39m             name=last_user_msg.name,\n\u001b[32m    205\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\miniconda3\\envs\\langchain_1.0_env\\Lib\\site-packages\\langchain\\agents\\middleware\\pii.py:153\u001b[39m, in \u001b[36mPIIMiddleware._process_content\u001b[39m\u001b[34m(self, content)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matches:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m content, []\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m sanitized = \u001b[43mapply_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sanitized, matches\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SSAFY\\miniconda3\\envs\\langchain_1.0_env\\Lib\\site-packages\\langchain\\agents\\middleware\\_redaction.py:271\u001b[39m, in \u001b[36mapply_strategy\u001b[39m\u001b[34m(content, matches, strategy)\u001b[39m\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _apply_hash_strategy(content, matches)\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strategy == \u001b[33m\"\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PIIDetectionError(matches[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m], matches)\n\u001b[32m    272\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown redaction strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mPIIDetectionError\u001b[39m: Detected 1 instance(s) of api_key in text content",
      "During task with name 'PIIMiddleware[api_key].before_model' and id '6d01d63c-9423-1915-2e69-cc9d43ab1f55'"
     ]
    }
   ],
   "source": [
    "# api key를 포함하여 agent를 호출해봅시다.\n",
    "messages = [\n",
    "    HumanMessage(content=\"내가 env 변수명 잘못 설정했나??\\n OPENAPI_API_KEY=sk-proj4a2fcd5a1bdbd09e4fdd020d07b6a4380c84fdb07be5f674c5fa8e39b35e\"),\n",
    "]\n",
    "\n",
    "''' 아래 코드는 실행시 PIIDetectionError가 발생합니다!\n",
    "PIIDetectionError: Detected 1 instance(s) of api_key in text content\n",
    "During task with name 'PIIMiddleware[api_key].before_model' and id '95c50dad-870c-5ce6-6178-0d9b216c4341'\n",
    "'''\n",
    "# response = agent.invoke(\n",
    "#     {\"messages\":messages},\n",
    "#     )\n",
    "\n",
    "# pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_1.0_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
